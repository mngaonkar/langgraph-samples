{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/berkeley_ai/lib/python3.12/site-packages/requests/__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n",
      "/opt/miniconda3/envs/berkeley_ai/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:777: UserWarning: Mixing V1 models and V2 models (or constructs, like `TypeAdapter`) is not supported. Please upgrade `Settings` to V2.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "# Import relevant functionality\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.messages import HumanMessage, ToolMessage\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from tools.visit_web_page_tool import VisitWebPageSyncTool\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "from langchain_openai import ChatOpenAI \n",
    "import os, json\n",
    "from typing import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END, MessagesState\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from dotenv import load_dotenv\n",
    "from functions.download_transcripts_func import download_transcripts_func\n",
    "from common.common import GraphState\n",
    "from tools.crawl_web_page_tool import CrawlWebPageSyncTool\n",
    "from tools.query_database_tool import QueryDatabaseTool\n",
    "from functions.initialize_database import initialize_database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    temperature=0,\n",
    "    model=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collections in the database: [Collection(name=langchain)]\n"
     ]
    }
   ],
   "source": [
    "tools = [CrawlWebPageSyncTool(),\n",
    "        QueryDatabaseTool(db_path=os.getenv(\"DB_PATH\"))]\n",
    "\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "async def tool_calling_llm(state: GraphState) -> dict:\n",
    "    \"\"\"Function to call the LLM with tools.\"\"\"\n",
    "    response = await llm_with_tools.ainvoke(\n",
    "        [HumanMessage(content=state[\"query\"])]\n",
    "    )\n",
    "    state[\"messages\"] = [response]\n",
    "    print(f\"LLM Response: {response}\")\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def should_continue(state: GraphState) -> str:\n",
    "    \"\"\"Condition to check if the tool call should continue.\"\"\"\n",
    "    print(f\"should_continue: state: {state}\")\n",
    "\n",
    "    if state[\"messages\"][-1].additional_kwargs[\"tool_calls\"]:\n",
    "        print(f\"Tool calls found in response, continuing with tool node, {state[\"messages\"][-1].additional_kwargs[\"tool_calls\"]}\")\n",
    "        return \"tool_node\"\n",
    "    \n",
    "    print(\"No tool calls found in response, ending the process.\")\n",
    "    return \"END\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decide_next_node(state: GraphState) -> str:\n",
    "    \"\"\"Decide the next node based on the state.\"\"\"\n",
    "    print(f\"decide_next_node: state: {state}\")\n",
    "    \n",
    "    messages = state[\"messages\"]\n",
    "    tool_messages = [msg for msg in messages if isinstance(msg, ToolMessage)]\n",
    "    \n",
    "    for msg in tool_messages:\n",
    "        if msg.name == \"crawl_web_page\":\n",
    "            return \"download_transcripts_func\"\n",
    "        elif msg.name == \"query_database\":\n",
    "            return END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = StateGraph(GraphState)\n",
    "builder.add_node(\"tool_calling_llm\", tool_calling_llm)\n",
    "builder.add_node(\"tools\", ToolNode(tools))\n",
    "builder.add_node(\"download_transcripts_func\", download_transcripts_func)\n",
    "builder.add_node(\"initialize_database\", initialize_database)\n",
    "\n",
    "builder.add_edge(START, \"tool_calling_llm\")\n",
    "builder.add_conditional_edges(\"tool_calling_llm\", tools_condition, [\"tools\", END])\n",
    "builder.add_conditional_edges(\"tools\", decide_next_node)\n",
    "builder.add_edge(\"download_transcripts_func\", \"initialize_database\")\n",
    "builder.add_edge(\"initialize_database\", END)\n",
    "\n",
    "graph = builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        +-----------+     \n",
      "        | __start__ |     \n",
      "        +-----------+     \n",
      "              *           \n",
      "              *           \n",
      "              *           \n",
      "    +------------------+  \n",
      "    | tool_calling_llm |  \n",
      "    +------------------+  \n",
      "         ..        ..     \n",
      "       ..            .    \n",
      "      .               ..  \n",
      "+-------+               . \n",
      "| tools |             ..  \n",
      "+-------+            .    \n",
      "         **        ..     \n",
      "           **    ..       \n",
      "             *  .         \n",
      "         +---------+      \n",
      "         | __end__ |      \n",
      "         +---------+      \n"
     ]
    }
   ],
   "source": [
    "graph.get_graph().print_ascii()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = await graph.ainvoke(\n",
    "#     GraphState(query=\"get all blogs from https://www.thecloudcast.net\"), debug=False\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Response: content='' additional_kwargs={'tool_calls': [{'id': 'call_TLh4uMFJlxBswtMftw5DJveY', 'function': {'arguments': '{\"query\":\"data management\"}', 'name': 'query_database'}, 'type': 'function'}], 'refusal': None} response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 123, 'total_tokens': 138, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_a288987b44', 'id': 'chatcmpl-Bc4EyXHeB1tPqmIUkZYLZlymT518V', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None} id='run--348a2017-f18f-42a2-9b6d-080ef71f5be8-0' tool_calls=[{'name': 'query_database', 'args': {'query': 'data management'}, 'id': 'call_TLh4uMFJlxBswtMftw5DJveY', 'type': 'tool_call'}] usage_metadata={'input_tokens': 123, 'output_tokens': 15, 'total_tokens': 138, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "Collections in the database: 1\n",
      "Search results:\n",
      "Result 1:\n",
      "[\"Aaron Delp (00:03.234)\\nGood morning, good evening, what if you aren't welcome back to the cloudca... (Distance: 1.3819793462753296)\n",
      "metadata: {'link': 'https://www.thecloudcast.net/2025/05/universal-data-representation-for-ai.html', 'source': 'transcripts/Universal_Data_Representation_for_AI.txt'}\n",
      "Result 2:\n",
      "[\"Aaron Delp (00:01.406)\\nGood morning, good evening, you are and welcome back to the Cloudcast. We'... (Distance: 1.5770093202590942)\n",
      "metadata: {'source': 'transcripts/AI_Impacts_Across_Organizations_&_Startups.txt', 'link': 'https://www.thecloudcast.net/2025/03/ai-impacts-across-organizations-startups.html'}\n",
      "Result 3:\n",
      "[\"Brian Gracely (00:03.694)\\nThree, two, one. Good morning, good evening, wherever you are. Welcome ... (Distance: 1.6602836847305298)\n",
      "metadata: {'source': 'transcripts/The_Early_AI_Journey_and_Learning_Curve.txt', 'link': 'https://www.thecloudcast.net/2025/05/the-early-ai-journey-and-learning-curve.html'}\n",
      "Result 4:\n",
      "[\"Brian Gracely (00:03.276)\\nAnd we're back. And as I mentioned at the top of the show, I want to di... (Distance: 1.7005794048309326)\n",
      "metadata: {'source': 'transcripts/AI_Augmenting_vs._Replacing.txt', 'link': 'https://www.thecloudcast.net/2025/04/ai-augmenting-vs-replacing.html'}\n",
      "Result 5:\n",
      "[\"Aaron Delp (00:01.004)\\nGood morning, good evening, if you are and welcome back to the Cloudcast. ... (Distance: 1.7046046257019043)\n",
      "metadata: {'source': 'transcripts/DevOps_Meets_Platform_Engineering.txt', 'link': 'https://www.thecloudcast.net/2025/04/devops-meets-platform-engineering.html'}\n",
      "decide_next_node: state: {'query': 'query all blogs having reference to data management', 'messages': [ToolMessage(content='[\"[\\\\\"Aaron Delp (00:03.234)\\\\\\\\nGood morning, good evening, what if you aren\\'t welcome back to the cloudcast. We\\'re coming to you live from our massive cloudcast studios here in Raleigh, North Carolina. And it is just Aaron this week, but we have a concept I feel like we\\'re going to dig into and with something we\\'ve talked about many times on the show in many different ways and that being data. But I feel like there\\'s something more here. There\\'s something we need to dig into. so we\\'re going to dig into this concept of universal data representation.\\\\\\\\n\\\\\\\\nfor AI and exactly what that means. And for that, have Joel Krisner, founder and CEO at Vue. So first of all, Joel, is it Vue or is it Vue.io? I want to make sure I get the names correct here.\\\\\\\\n\\\\\\\\nJoel (00:47.333)\\\\\\\\nView.io is the domain. We\\'re just called View though. Thanks for asking.\\\\\\\\n\\\\\\\\nAaron Delp (00:50.434)\\\\\\\\nPerfect, absolutely. So Joel, welcome to the show and give everyone a quick introduction, please.\\\\\", \\\\\"Joel (00:56.101)\\\\\\\\nYeah, absolutely. So Aaron, thanks for having me and to all of your listeners, thanks for tuning in. My name is Joel Krisner. I\\'ve been in tech for just about 30 years, did a long run at big companies like Cisco and Dell, did a bunch of startups and here we are at Vue, making it easy for enterprises to take advantage of artificial intelligence. So my role in the company is keep the wheels on the bus, keep the lights on and build the core of the product and we\\'re getting some good traction and good success. So I\\'m excited to be here.\\\\\", \\\\\"Aaron Delp (01:23.896)\\\\\\\\nFantastic. So yeah, as I mentioned, our big topic today is kind of everything data, right? And how to represent it, how to embed it into AI systems, because I feel like there\\'s a lot of folks out there, it\\'s like, I have a model and I just fine tune it, or I just train it, or I just set up a rag pipeline. But a lot of people don\\'t quite understand what that exactly entails, right? And so let\\'s first of all kind of start at the challenge. Like what is...\\\\\\\\n\\\\\\\\nthe challenge of data, structured, unstructured in most organizations today, and what is behind this concept of universal data representation.\\\\\\\\n\\\\\\\\nJoel (02:06.833)\\\\\\\\nThat is a fantastic question. And I think a lot of people do start their AI journey perhaps a little prematurely because they don\\'t have what I would call a solid horizontally applicable data management layer in place.\\\\\", \\\\\"And there\\'s a lot that goes into that. There\\'s governance, there\\'s provenance, there\\'s lineage, having an understanding of where your data is, the way that it\\'s structured, who\\'s authoring this data, how it needs to be secured. That\\'s all part and parcel of a core data management system. And the better prepared you are in that endeavor, the better you\\'re going to be when it comes to deploying AI.\\\\\\\\n\\\\\\\\nData for data management sake is very different than data for AI systems.\\\\\", \\\\\"with AI systems, there\\'s obviously the training and the fine tuning that can go into a model. I think the vast majority of companies out there, when I say vast majority, there\\'s a lot of little companies, right? Not everybody has the resources, the people, the knowledge, the time, the money to go out and train and build their own models and fine tune them. So the vast majority of people are going to be using off the shelf models. And that brings up the next question. How do I take advantage of that model using my own data? And a lot of people think\\\\\\\\n\\\\\\\\nthat it\\'s very easy. I\\'m just going to drag and drop a file into my model and do rag. That\\'ll only get you so far. What we found is that the best approach, or one of the best approaches, there\\'s several, and you\\'ll want to use multiple, right? This is just one of them, is building out a metadata and feature store that looks at the contents of your data, understands what the type of the data is.\\\\\", \\\\\"Joel (03:50.807)\\\\\\\\nExtracts the geometry of that data the key terms if there\\'s any kind of schema in that data identifies the schema and then flattens the representation into something queryable understands the data types that are in the various values and builds an inverted index so that you can see how the Subcontents of that file relate to other subcontents like if I have the sentence the quick brown fox jumped over the lazy dog I\\'d want to know that the word is at positions zero and six and it\\'s you know three tokens away\\\\\\\\n \\\\\\\\nfrom QUIC or whatever the case may be. That\\'s what we call universal data representation at Vue. That\\'s one of the fundamental things that we do. It\\'s kind of our secret sauce where we can take any heterogeneous piece of data and transform it into this homogenous representation. So it has the same structure, whether it\\'s a database table or if it\\'s a JSON object or the contents of a PowerPoint file. Once you have that,\\\\\", \\\\\"That puts you then in a position to begin intelligently embedding using an embedding model of your choosing. And the resultant embeddings can then be packed into a vector database along with metadata and the contents that can then be a feed to your retrieval augmented generation pipeline. So what that will allow you to do is if you have something that sits in between the user and the model that is able to then query that metadata feature store to find relevant\\\\\\\\n\\\\\\\\ncontextual documents, that prompt can then be packed and fed to the model with context allowing the LLM to give a more intelligent data-centric response rather than just what it\\'s been trained on. So I said a lot. I\\'ll pause there, Aaron, and give you an opportunity to ask any clarifying questions on that.\\\\\", \\\\\"Aaron Delp (05:33.921)\\\\\\\\nWell, yeah, maybe one, because I think it\\'s worth touching on again or clarifying maybe a little bit more. mean, the most prevalent solution I\\'m seeing in customers I speak to is exactly what you\\'re saying, like taking a foundational model or a frontier model, however we want to call those these days, and then simply adding a rag pipeline to it in most cases. I don\\'t see a lot of organizations necessarily\\\\\\\\n\\\\\\\\ntaking the time to fine tune as much, you know, I kind of, don\\'t, it\\'s hard to put a number on it, but like, you know, 80, 20, 90, 10, somewhere thereabouts, but I think the amount of organizations taking the time or having the staff or having the resources or, you know, the amount of GPUs to do fine tuning, I\\'m just not seeing that any as much, but I wanted to clarify is that,\\\\\\\\n\\\\\\\\nWhat you\\'re seeing as well when it comes to this data representation, it\\'s mainly rag pipelines and vector databases, or is that maybe a little bit off?\\\\\", \\\\\"Joel (06:41.349)\\\\\\\\nI\\'d say that is the overwhelming majority. And the primary reason for it is even though OpenAI launched Chad GPT in November 2022, so two and two and a half years ago, the learning curve, especially as it relates to, you know, training networks and building models, learning curve is still pretty steep, even though there is just a tremendous amount of information out there, especially when you start talking about\\\\\\\\n\\\\\\\\nengineers in the enterprise, right? They\\'ve got a day job, you know, and since there\\'s not a measurable ROI that someone could just apply to a potential AI project to say, we know that if we embark on this journey, we\\'re going to cut customer support costs by 30%. Right? So they, it\\'s very hard to tie a dollar amount to that. It\\'s, it\\'s very difficult to create then an incentive.\\\\\", \\\\\"for someone to go off and learn it if they don\\'t know that they\\'re going to get the ROI out of the project because 30 % of somebody\\'s time is what, 12, 13 hours a week, something like that, that they could be doing what they\\'re supposed to be doing. So there\\'s a time commitment certainly to doing it. There\\'s a risk associated with it. So I think what a lot of people have opted for is just taking advantage of RAG because it\\'s not a perfect solution by any means. And certainly there\\'s a lot more that you can do\\\\\\\\n\\\\\\\\nwith training your own models and fine tuning existing models. But there is one part science and one part voodoo in RAG in that the better you\\'re able to parse and dissect your data into features and the better you are able to tune the way that you retrieve data and compact that into a useful prompt for the model, you can get extremely good levels of accuracy. We\\'re seeing customers get north of 90, 92 % accuracy.\\\\\\\\n\\\\\\\\nAaron Delp (08:16.078)\\\\\\\\nSure.\\\\\", \\\\\"Joel (08:37.171)\\\\\\\\njust using rag and an off-the-shelf foundational model, whether it\\'s, you know, like Quinn or Lama or something along these lines.\\\\\\\\n \\\\\\\\nAaron Delp (08:45.432)\\\\\\\\nYeah. And a follow-up question to that too, because I want to understand too, what we\\'re really talking about here when we talk about this kind of universal data representation, at the end of the day, okay, whether it\\'s structured data or unstructured data or a combination of both, what we\\'re looking at here is tooling and a workflow and a pipeline that is taking those files that are, I\\'ll say, customer-specific or organization-specific.\\\\\\\\n\\\\\\\\nand then running them through this pipeline and this set of tools with the output being the embeddings that would go in a rag database like a chroma or a pine cone or something else like that. Is that a correct way to kind of think about this workflow of like how it gets from say a PDF that is customer specific into something that, hey, I can write a prompt and\\\\\", \\\\\"it will actually spit out an answer based off of that. Is that a correct way to think about it?\\\\\\\\n\\\\\\\\nJoel (09:47.909)\\\\\\\\nYeah, that\\'s definitely the right way to think about it. So if your starting point is a PDF, the first thing you\\'re going to do is detect that it is a PDF. Somebody could send you a Word document that\\'s been renamed to .pptx and all of your parsers are just going to explode. So you want to figure out what it is. Second is you want to extract key terms, top terms, general metadata out of the document if it\\'s structured, get the schema. From there, you want to take that source content and break it into what we like to call semantic cells.\\\\\\\\n\\\\\\\\nthose cells are contextually relevant pieces of the document. So if you\\'re looking at a PDF, you might take paragraph one as a cell and then paragraph two as a cell.\\\\\", \\\\\"You want to then intelligently chunk it in accordance with your embedding model\\'s boundaries. It might only accept a certain number of tokens, so maybe that\\'s 256. So you chunk it 256 tokens at a time from each semantic cell, thus yielding semantic chunks. And there\\'s a lot of wizardry you can do in there too. You might want some overlap amongst those chunks. That way you\\'re not losing contextual pieces as you chunk.\\\\\\\\n\\\\\\\\nFrom there, and of course that\\'s a space versus fidelity trade off, right? From there, you generate embeddings against that content using the embedding model you specify. And that plus, in our case, a whole lot of other metadata gets fed into a vector store. One that we absolutely love is PG Vector. And you know, the community has been gravitating toward it quite a bit. One of the interesting things that you can do when you have something that is like the UDR concept that I described,\\\\\", \\\\\"You can also create hierarchical metadata retrieval capabilities inside of your rag pipeline. So you\\'re no longer confined to just doing.\\\\\\\\n\\\\\\\\nJoel (11:29.849)\\\\\\\\nCosine distance searches or Euclidean distance searches or inner product searches to find Contextual data that\\'s been embedded that matches or as close to what your prompt contains You can also start looking at other sources like your metadata and perhaps even graph representations You know, maybe once you\\'ve gone through that fine grained metadata extraction you understand who the author is and you might be able to identify other documents that have been written by that author that you might want to include as context because perhaps that person is a domain expert\\\\\\\\n\\\\\\\\nin that subject. So once you have that content embedded, the baseline is doing a distance or a similarity search or an inner product search against your vector store. But you can further augment it using that rich metadata that you\\'ve generated.\\\\\", \\\\\"Aaron Delp (12:14.7)\\\\\\\\nFantastic. And a follow-on question, while I was thinking through some of these workflows, I think something else that comes to mind too is not just data quality and data representation, but this concept of\\\\\", \\\\\"Data privacy, but I almost feel like that\\'s too generic of a term. Let me give you an example. A highly regulated industry, like take healthcare or financial services or somebody like that who maybe they want to do an off the shelf model, but they want to set up a rag pipeline against it because at the end of the day, there\\'s gonna be a lot of customer specific data, PII data, other things like that.\\\\\\\\n \\\\\\\\nOr it\\'s highly sensitive in the fact that like a lot of organizations, when I talk to them, they\\'re not even considering public cloud for something like this for, you know, serving the data, serving the models, etc. And so how does that fit in of like, do you sometimes have like, the the rag pipeline and the data be on prem, but it\\'s utilizing cloud services to actually generate the the text or\\\\\\\\n\\\\\\\\nWhat kind of things are you seeing when it comes to highly regulated spaces or areas where that data really is like the keys to the kingdom, if I use that term.\\\\\", \\\\\"Joel (13:39.013)\\\\\\\\nYeah, Aaron, that\\'s a great question. And it\\'s a tough one because all of this AI stuff, I like to say was really built for a born in the cloud cloud native developer.\\\\\\\\n\\\\\\\\nthe majority of us have been conditioned to assume that when we\\'re doing anything AI, we\\'re going to be using a third party public cloud API to do certain aspects of that. fact of the matter is you don\\'t have to. And there\\'s nothing wrong with using that as long as you\\'re safe and using your data in a way that is appropriate given the sensitivity of the data. lot of the customers that we talk to are the mid to high end of the enterprise.\\\\\\\\n\\\\\\\\nThe vast majority of their data is still behind the firewall because it\\'s confidential. It\\'s protected by regulation. There\\'s company policy. There\\'s intellectual property. There\\'s financials. There\\'s a number of re not to mention, I mentioned, you know, regulatory, but like HIPAA and others.\\\\\", \\\\\"good luck getting that data and then not to mention just the general fear that whoever you send that data to might use it in subsequent training, right? Or they might get compromised. It\\'s highly unlikely, but they could. So there are a lot of businesses that want to do everything end to end behind the firewall.\\\\\\\\n\\\\\\\\nAaron Delp (14:39.798)\\\\\\\\nYep.\\\\\\\\n\\\\\\\\nJoel (14:57.199)\\\\\\\\nThe beauty is there\\'s essentially tools that allow you to do just that and shameless plug. Of course, that\\'s my company\\'s bread and butter. We deploy in 15 minutes and you chat with your data inside of 20. Once you deploy on a, on a Linux machine behind your firewall, it is literally all enabled by a lot of open source software. And of course, bespoke software that we\\'ve built that runs on premises behind the firewall. And you can take advantage of any model from the internet. The difference is\\\\\", \\\\\"you\\'re not having the conversation against that model on somebody else\\'s server. You\\'re actually pulling that model down to your data center and doing all of your embedding and inference and completions locally. So the tooling absolutely does exist. There\\'s definitely an appetite for it. At least that\\'s what we\\'re seeing.\\\\\\\\n\\\\\\\\nAaron Delp (15:40.729)\\\\\\\\nYeah, yeah, that makes sense. And let me kind of ask maybe a follow on because I love to explore life cycles of all of these. So let me give you another example. So first model comes out, right? You\\'ve got everything set up, you\\'ve got your embeddings, everything\\'s working. And I\\'ll just go back to the old, you know, application terms. It\\'s one dot o of the model, right? And a topic we\\'ve explored many times on this shows is a lot of organizations\\\\\", \\\\\"There\\'s two ways to handle the data model. And I\\'ll just refer to the drift over time, right? Like you can constantly add more embeddings in, you can constantly add more data, you can improve the quality of it, but there\\'s two theories to that. Number one is you take that 1.0 model and you just continually improve it. It\\'s always a 1.0 model. I\\'ll call it the ChatGPT model, right? Like even though there\\'s ChatGPT 4, the answers you get, you know,\\\\\", \\\\\"a couple months ago versus now like, sometimes the answers are different and you don\\'t know why, right? And is it just the quality changed? Is it the dataset changed? And so what I\\'ve seen, especially again, going back to highly regulated spaces is almost this versioning of the dataset and the model. I\\'m going to have this model with this version of the database and we\\'re going to call it 1.0. And then eventually we\\'re going to roll out 1.1, which is going to be an improvement.\\\\\\\\n \\\\\\\\nbut it\\'s almost like a versioning and control aspect. And so like, what are you seeing and what is your recommendations on how to handle this over time? Of course we want continuous feedback and a continuous improvement, but how do you handle that unpredictability that some organizations would require?\\\\\", \\\\\"Joel (17:28.271)\\\\\\\\nYeah, great question. So, you know, thankfully there are a lot of, I hate to call them standardized, but there are standardized assessments that models can be evaluated against to give an indicator of their level of accuracy.\\\\\\\\n\\\\\\\\njust being able to answer questions. I think from an enterprise perspective, if you\\'re using a model that is outside of your control, you need a studio of sorts that will allow you to connect a model to one or many different data stores. And those data stores have all of the contextual metadata and embeddings that have been generated against that data so that you can test how the model will handle certain types of questions and certain types of prompts.\\\\\", \\\\\"it within that studio, you should have the ability to modify and manage system prompts. So what you tell the model, give it some boundary conditions on how to respond, what personality to take on, what is in limits and what is off limits, and also the ability to make some adjustments to how retrieval is performed to enrich the prompt for retrieval augmented generation, of course. So if you wanted to restrict it to a certain number of entries and then pull the entire set of documents associated with those entries,\\\\\", \\\\\"or just subsets of those documents or do some form of re-ranking. That kind of studio will allow you to quote unquote prototype or beta test an experience. The experience is at the end of the day what you\\'re looking for, right? It\\'s I want to put this thing out in the wild that is informed by this set of data and have, you know, some reasonable understanding and expectation of how the experience is going to go for somebody who\\'s asking questions. A studio can provide you exactly that. You marry a model to one\\\\\\\\n\\\\\\\\nor more knowledge bases with retrieval parameters and system prompts. And once you dial that in.\\\\\", \\\\\"Joel (19:19.025)\\\\\\\\nYou know, you can package that and then go deploy it, whatever you want to do. The beautiful thing about that is you can keep that same set of configuration and just replace the model with version 1.1 or 1.2 and then you can test it again and see what the changes look like. And if you like those changes, then you can go deploy the changes. So we\\'ve got a capability like that called our Assistant Studio built into the product where I can marry a model to a set of retrieval parameters, to a set of knowledge bases.\\\\\", \\\\\"and bang on it, then ask it all the questions that I want to see how it responds until you feel that it\\'s behaving the way that you want and responding the way that you want. And once it is deployed on the internet, deployed to Slack, deployed to Teams, put an SMS interface in front of it. And the nice thing about that is you can make changes over time too. And if you find one that works even better, you can replace it in place of the one you\\'ve already deployed behind the scenes with no disruption.\\\\\\\\n\\\\\\\\nAaron Delp (20:17.302)\\\\\\\\nNice, nice. And let me ask you this, because I think this is really worth digging into as well. We\\'re I think it\\'s something that you hear, you know, certain tools and certain technologies, you know, whether it\\'s the frontier models or, you know, the kind of rag database or some of these other things. I feel like we\\'re starting to get to the point where I\\'ll use I don\\'t want to say standard.\\\\\", \\\\\"because that\\'s taking it too far and making it too official. But I will just simply say patterns are emerging as far as these are the certain tool sets and this is what it looks like, whether you take this kind of model, take this kind of reg database, take this kind of tooling and kind of string it all together. To kind of go back to DevOps days, it\\'s the equivalent of building the CI CD pipelines and certain tools and patterns developed over time. Are we to the point?\\\\\\\\n \\\\\\\\nwhere those patterns are starting to develop where when you\\'re talking to customers and they want to get going and they want to get going fast, you kind of say, okay, use this model, use this technology, use this technology, use this tool. Here\\'s how you string it all together. Cause by the way, it\\'s proven, it works. There\\'s lots of other customers out there doing it today. What kind of recommendations do you have for something like that?\\\\\", \\\\\"Joel (21:38.885)\\\\\\\\nYeah, that\\'s a great question. And you actually took it in a direction that I was not anticipating. I was thinking about it from the perspective of like, you know, I remember when cloud was this new fan dangled thing and it only took.\\\\\\\\n\\\\\\\\nI would say, you know, like maybe three years before the API war on object storage was won by Amazon S3, you know, just became a de facto type of thing. A very similar type of thing has already happened in my opinion with, you know, the front end of prompting a model and that\\'s OpenAI\\'s API, their data structures, response structures.\\\\\\\\n\\\\\\\\nAaron Delp (21:59.479)\\\\\\\\nYes, perfect example. Absolutely. Yes.\\\\\\\\n\\\\\\\\nAaron Delp (22:12.033)\\\\\\\\nAPIs, yep.\\\\\\\\n\\\\\\\\nJoel (22:14.801)\\\\\\\\nWe\\'re starting to see some de facto, I call it de facto standards coming out through the likes of MCP is another example of that. But I think more to your question about the actual end user experience and the use case for that experience. That\\'s a tough one.\\\\\", \\\\\"to answer horizontally. Horizontally, it\\'s easy enough to say, if you\\'re going to do a customer support chatbot, you\\'re going to be loading in all of your customer support tickets, your product, product manuals, troubleshooting guides, account related types of things. I\\'m blending customer support and technical support here, so forgive me for that. I\\'m conflating too,\\\\\\\\n\\\\\\\\nAaron Delp (23:00.078)\\\\\\\\nNo problem. No problem.\\\\\\\\n\\\\\\\\nJoel (23:01.999)\\\\\\\\nYou\\'ve got a corpus of data and then you define a, you make sure that you include some overlap in your chunking strategy. That way, you you don\\'t chunk right in the middle of a thought that\\'s important contextually. want to, you know, try to capture every whole thought that you can. And then you build your system prompt to say, you are a helpful customer support chat bot provided for you before the user question is a series of, you know, helpful pieces of contextual information. And at the end,\\\\\", \\\\\"you will also find links to those documents if you want to share those with the user. Respond in a friendly way, don\\'t answer questions that you don\\'t know how to answer and try not to lean on your training, rely primarily on the provided context. I think it\\'s hard to nail down a de facto out of that, but I think that, you know, the world is starting to converge on what the best practice, for instance, system prompt is and chunking strategies are for various use cases like customer support, technical support, even, you know, for,\\\\\\\\n\\\\\\\\nAaron Delp (23:59.524)\\\\\\\\nYes.\\\\\\\\n\\\\\\\\nJoel (24:01.778)\\\\\\\\nsome more complex domains, but where it gets really tough, and one of the reasons that I firmly feel that it\\'s difficult to get that solid horizontal data management strategy in place, and you\\'ll see why I\\'m saying this in a second.\\\\\", \\\\\"Data and data management are extremely fragmented. The farther up the data stack you go, the more bespoke the data becomes. So it\\'s good to have that generalized set of principles around chunking strategy and system prompts and retrieval optimizations and all of these other things. But again, the farther up the data stack you go, the more bespoke it becomes. So the more you have to really understand your data to be able to tune those things to get the experience that you want.\\\\\\\\n\\\\\\\\nAaron Delp (24:43.938)\\\\\\\\nYeah, that makes perfect sense. I love it. I love it. And actually, I think that that\\'s good point for us to kind of end on for today. So Joel, if anyone out there is kind of interested in this, wants to ask you a question, wants to kind of dig in more, what\\'s the best place for them to get started?\\\\\", \\\\\"Joel (25:01.197)\\\\\\\\nAbsolutely, just go over to view.io, V-I-E-W.io. Check us out and if you have any questions, email me, Joel, J-O-E-L, at view.io. I\\'m here for it. We\\'ve got a great team that\\'s passionate about this stuff. We\\'re constantly learning like everybody else is and we can\\'t wait to talk to them.\\\\\\\\n \\\\\\\\nAaron Delp (25:19.63)\\\\\\\\nAll right, well Joel, thank you very much for your time today and everyone out there, thank you very much for listening this week. And if you enjoy the show, please of course, tell a friend. If you can leave a review wherever you get your podcast, please leave us a review as well. And of course, we\\'re always looking for feedback and ideas for guests as well. Show at thecloudcast.net. On behalf of Brian and myself, thank you everyone for listening and we will talk to everyone next week.\\\\\"]\", \"[\\\\\"Aaron Delp (00:01.406)\\\\\\\\nGood morning, good evening, you are and welcome back to the Cloudcast. We\\'re coming to you live from our massive Cloudcast DDoS here in Raleigh, North Carolina. It is Aaron this week and I have not one, but two great guests. And actually two folks in the industry we\\'ve been meaning to talk to for a while. actually, gosh, I think scheduling this podcast actually became a running joke between the three of us, but we finally got schedules to align and everything, you know, going in the direction we needed it to.\\\\\\\\n\\\\\\\\nbut we\\'re going to be talking it\\'s a bit of a grab bag today, almost like a little bit of like AI impacts in the industry. And so for that, we\\'ve got John Duran, sales. Actually, I\\'m gonna, I\\'ll edit that one. John Duran, AI data and solutions at WWT or worldwide technology, if you\\'re not familiar with WWT. And Drew McFarlane, product strategy at Infoblox. Gentlemen, how are you doing?\\\\\\\\n\\\\\\\\nJon Duren (00:59.672)\\\\\\\\nDoing great here.\\\\\", \\\\\"Druce (00:59.738)\\\\\\\\nI\\'m doing great.\\\\\\\\n\\\\\\\\nAaron Delp (01:01.792)\\\\\\\\nWhy don\\'t you give each other a quick introduction, Drew, so why you go first,\\\\\\\\n\\\\\\\\nDruce (01:06.384)\\\\\\\\nOkay, so this is John Duren over there. So my name is Drew McFarland. I\\'ve been working for Infoblox for about five or six years and I\\'m in the strategy organization. I have a long history of basically cybersecurity and startups. So jumping back and forth between large organizations, smaller organizations. So large organizations like my startup information because I can talk about the small ones and vice versa.\\\\\\\\n\\\\\\\\nAaron Delp (01:09.18)\\\\\\\\nYeah, that\\'s right.\\\\\\\\n\\\\\\\\nAaron Delp (01:39.348)\\\\\\\\nJohn?\\\\\", \\\\\"Jon Duren (01:40.738)\\\\\\\\nYeah, so I\\'ve been with World Wide Technology now, closing in on 17 years. It\\'s been a long ride. But like Drus and myself, I\\'ve in the past been through a number of startup organizations, a lot of startup companies and learned a lot of lessons there. I actually kind of miss a lot of that time. And I think that\\'s what led Drus and I to our other podcast about startup organizations.\\\\\\\\n\\\\\\\\nAaron Delp (02:04.692)\\\\\\\\nYes, absolutely. Which by the way, link to that in the show notes, definitely go check it out. It is the Startup Lantern Podcast. Really good, really informative show. So everyone definitely go give that a listen. So what I wanted to do was kind of just jump in to a little bit of AI impacts across organizations, right? Like I want to talk about security a little bit, talk about startups.\\\\\", \\\\\"a little bit, not AI startups, actually how AI is impacting startups. then, John, this is probably a recreation of a couple of our dinner conversations, you know, with the day jobs at times of like, well, what\\'s going on with AI and enterprises and even small and medium customers as well. So we\\'re going to kind of dig in there. So, let me ask you this, like AI has kind of thrown the world of cybersecurity a big curve ball.\\\\\\\\n\\\\\\\\nJon Duren (02:38.677)\\\\\\\\nYou\\\\\\\\n\\\\\\\\nAaron Delp (02:58.749)\\\\\\\\nI feel like right. And so what are you seeing? What\\'s the impact on it? And what kind of typical conversations do you get?\\\\\", \\\\\"Druce (03:06.778)\\\\\\\\nboy. So first of all, you know, if anybody has gone to a cybersecurity trade show, anytime in the last year, you know, every single company sort of lists, you know, their commitment to AI as being their unique differentiator. And the reality is, you know, everybody is struggling to figure out exactly what the best way of using AI is. And when you start trying to use the technology before you actually have a use case, you\\'re kind of doing the cart before the horse.\\\\\\\\n\\\\\\\\nJon Duren (03:11.832)\\\\\\\\nHa ha.\\\\\", \\\\\"Druce (03:35.248)\\\\\\\\nThe problem is the threat actors out there have no question about how they\\'re using it. They\\'re using it to great effect. The entire, especially when you think about what people are traditionally thinking about these days, which is chat GPT and the large language models. These things are tailor-made for trying to figure out how to create campaigns that will enable people to actually engage and click on things that they weren\\'t supposed to.\\\\\\\\n \\\\\\\\nYou know, the, to a great extent, the, the entire cybersecurity organization, the entire community is kind of playing a little bit catch up, which it usually always does with the threat actors. The threat actors usually are, are pretty crystal clear about what they\\'re trying to do. and, we\\'re trying to figure out how to block the stuff that they\\'re coming up.\\\\\", \\\\\"Aaron Delp (04:27.336)\\\\\\\\nYeah, no, that\\'s really good. Thank you. And let\\'s kind of move on to kind of the domain of your podcast. And we talked a lot of startups here, but a lot of the startups we talked to tend to be in the AI space or I will completely admit there are startups that kind of I\\'ll use the term AI wash themselves into being an AI company at times now. And so like\\\\\\\\n\\\\\\\\nJon Duren (04:52.462)\\\\\\\\nyou\\\\\\\\n\\\\\\\\nAaron Delp (04:56.318)\\\\\\\\nIf you take a second and step back from AI specific startups, how is AI really impacting how entrepreneurs and founders out there think? how do you launch a company that\\'s a non AI company these days? Because, you keep hearing all the time that the VC markets aren\\'t necessarily good and interest rates are up. And so all these other things that could potentially impact, you know, doing a startup these days. so, well, what\\'s your thoughts?\\\\\", \\\\\"Druce (05:28.242)\\\\\\\\nSo I\\'ll tell you, I\\'ll start and I\\'ll let John sort of drive it home. First of all, obviously, if you\\'re trying to do a startup right now, and there\\'s always the prospect of I\\'ve got to go out and get VC funding or something, you\\'ve got to have something to... And if you have the word AI somewhere in your title, or at least the description of what it is that you do, you\\'ll get a callback where you might not get any interest if you\\'re not doing that.\\\\\\\\n\\\\\\\\nJon Duren (05:45.379)\\\\\\\\nyou\\\\\\\\n\\\\\\\\nDruce (05:58.034)\\\\\\\\nThere\\'s that and I\\'m sure that there\\'s a degree of that where people are just kind of throwing AI into the mix just so that they can get some level of attention. Now, having said that, don\\'t want to downplay that too much because honestly, if you\\'ve got a startup right now and you\\'re not thinking about exactly how to bake in the fundamental tenets, the capabilities of AI right now, you are definitely going to be left behind.\\\\\", \\\\\"Your company may not necessarily have to be an AI company, but you have to be using AI. You you\\'ve got to be using AI, you know, in the development chain. You\\'ve got to be using it in the supply chain. You\\'ve got to be using it to, it just, it leverages everybody\\'s capabilities. And that\\'s one of the biggest, the biggest problems that you end up seeing with a startup is how do you leverage the resources that you have so that you actually can go as long as you can without taking in money.\\\\\\\\n\\\\\\\\nThe best way of being able to do that right now is with all the different tools that have suddenly flooded the market that help you be more effective.\\\\\\\\n\\\\\\\\nJon Duren (07:06.83)\\\\\\\\nI think from my perspective, I would extend that just the tools, the availability of tools now that AI is making capabilities for entrepreneurs, startups, you know, some of the things we cover in our podcast are about how to use your money, when to float money, when to spend money.\\\\\", \\\\\"AI now makes so much capability available to that founder, to the entrepreneur, without having to hire in some cases. The ability, I mean, even something just as simple as, you know, asking a chat bot to role play a venture capitalist against me and let me practice my pitch. I mean, something that simple is extremely powerful when you\\'re on limited funding, when trying to start a company and AI tools probably are the great equalizer. They give every entrepreneur the ability to act like\\\\\\\\n\\\\\\\\nthey already have a great amount of funding.\\\\\", \\\\\"Aaron Delp (07:57.894)\\\\\\\\nAnd so, John, I\\'ll kind of add some personal experience to all of that too, because, you know, at the end of the day, this podcast has been a nice side hobby over the years that has grown. And while we haven\\'t taken venture capital funding yet here at the Cloudcast, we certainly are like always considering and especially when it comes to certainly like media kind of things, like there\\'s always new tools and there\\'s always something going on and there\\'s always, you know, advancements in the space. And\\\\\\\\n \\\\\\\\nJon Duren (08:13.23)\\\\\\\\nYet.\\\\\", \\\\\"Aaron Delp (08:27.78)\\\\\\\\nhere before too much longer, we\\'re going to be doing, it\\'s almost like an annual or every couple of years kind of revamp of our tools and our tool chain. And it is super interesting to me in talking to others in the podcasting community, how much AI has potentially impacted that and like saved all the summarization or prepping for shows or, we\\'re not quite to agentic workflows where it\\'s publishing podcasts, but it\\'s really interesting.\\\\\\\\n\\\\\\\\nJon Duren (08:51.468)\\\\\\\\nHahaha\\\\\\\\n\\\\\\\\nAaron Delp (08:55.36)\\\\\\\\njust in our little space, whether it\\'s just a hobby or a business, how much it can impact things. Go ahead, Jules.\\\\\\\\n\\\\\\\\nDruce (09:01.662)\\\\\\\\nI remember and I\\'m dating myself with this reference, but I\\'m suspecting that the people on the, at least I\\'m doing this podcast with might actually remember this. Back in the earliest days of the internet, back when Bill Gates was still the CEO of Microsoft and they had pretty much ignored the entire internet revolution up until a certain point.\\\\\", \\\\\"And then finally Bill Gates decided to sit down and he installed Netscape on his PC and he explored the internet. And it was a, it was a transformative moment for him. And he broadcast out to the entire company. want everybody to tell me a business plan of how you are planning on using the internet in your particular product. And I want that within the next two or three days. And you\\'re like, this is how transformative this is. And if there\\'s an organization out there,\\\\\\\\n\\\\\\\\neven if it\\'s not an AI organization, even if it\\'s not a tech organization, if your CEO isn\\'t basically sort of throwing things down, legal department, how are you planning on using it? QA, how are you, like everybody out there needs to be figuring out exactly how they are planning on using this new tool because it\\'s gonna be a reality. And if the company is not utilizing that, they\\'re not being effective.\\\\\\\\n\\\\\\\\nAaron Delp (10:19.774)\\\\\\\\nYeah, absolutely. Absolutely. So go ahead, John, please. That\\'s fine. Not a problem.\\\\\", \\\\\"Jon Duren (10:21.878)\\\\\\\\nAaron, before we move on, let me pause you. I\\'m gonna have to take a dog out of here. You\\'re probably picking up some noise. I\\'m gonna stop this before, okay, I\\'ll be right back.\\\\\\\\n\\\\\\\\nDruce (10:26.341)\\\\\\\\nHa ha!\\\\\\\\n\\\\\\\\nDruce (10:33.138)\\\\\\\\nIt\\'s good that we can splice this together.\\\\\\\\n\\\\\\\\nAaron Delp (10:38.158)\\\\\\\\nno, absolutely. All I need to do is like, I could just, I just put it in the show notes to remind myself that there\\'s an edit I got to do. and then we just cut and splice it all together. Like it\\'s actually super easy. Well, it\\'s less easy on the, on the video side because I\\'m just not as good with those tools, but on the audio side, it\\'s super easy. So are you guys audio and video?\\\\\\\\n\\\\\\\\nDruce (11:01.906)\\\\\\\\nWe\\'re actually primarily just video. Yeah, so our primary distribution channel is YouTube and LinkedIn.\\\\\\\\n\\\\\\\\nJon Duren (11:04.75)\\\\\\\\nThank\\\\\", \\\\\"Aaron Delp (11:13.032)\\\\\\\\nNice. Okay. Fantastic. Good. Well, I will definitely be picking your brains then you know what, while we\\'re talking about this on the side here. I will definitely be picking your brains because I\\'m definitely at that point I need to start updating our tools and updating our workflows. So, all right, we\\'ll jump back in. What I\\'ll do is we\\'ll just give it a couple seconds of silence so that I can tell where to make the cut. And then what I\\'ll do is I\\'ll jump into our next topic.\\\\\\\\n\\\\\\\\nAaron Delp (11:47.818)\\\\\\\\nAll right, so that\\'s really good feedback from both of you about that. And let\\'s also maybe move on a little bit to customer conversations. All three of us on a pretty regular basis talk to customers and really kind of across the board from small, medium customers all the way to pretty decently large enterprise customers and global customers. So let\\'s maybe separate some hype from some practical, if you will, because\\\\\", \\\\\"I know John and I have had conversations about this before of like where organizations typically are in their AI journey isn\\'t necessarily where the hype cycle is, right? There\\'s not a lot of organizations out there. You know, the press and the news might not want you to believe it, but there\\'s probably not a lot of people maybe exploring agent-agate AI, but certainly not necessarily implementing it at this point. And so where are organizations here in early 2025?\\\\\\\\n \\\\\\\\nJon Duren (12:29.262)\\\\\\\\nyou\\\\\\\\n\\\\\\\\nAaron Delp (12:47.198)\\\\\\\\ntheir AI journey. John, do you want to go first on this one?\\\\\\\\n\\\\\\\\nJon Duren (12:49.71)\\\\\\\\nYeah, I\\'ll jump in that. So that\\'s an interesting question and it\\'s one that actually...\\\\\", \\\\\"gets asked in a lot of the customer engagements and briefings that we participate in. I think the answer is, while we would all like to think the chatbot is in the past, it\\'s really not. Most of the customers that I interact with have deployed a chatbot. It\\'s in some form of limited production in the organization. They\\'re trying to add data sources to it so they can make it smarter across more information in the organization.\\\\\\\\n\\\\\\\\nBut I don\\'t think that\\'s where we\\'re really, I think that\\'s the state of education, learning and experimenting in most organizations. What\\'s happening now is a shift of focus toward implementing the features and functions, the AI features and functions that are being made available and quickly becoming available in all of their core software packages, the applications and software that run the company every day that the users, the employees, the customers are already engaged in.\\\\\", \\\\\"And when we talk about agentic, you\\'re right. In private build, most customers are not yet experimenting with building and developing agentic AI. But many of them are beginning to turn on agentic features in the packages they\\'re already using. For instance, just something as simple as SharePoint now has agentic agents that you can start and use to make searchable access to different folders, files, teams rooms, things like that. I know ServiceNow and Salesforce are both\\\\\", \\\\\"implementing agentic capabilities as many, many more. And I think we\\'re going to see a shift for a while as budgets and focus really turns toward how do we enable these features? How do we evaluate and enable these features? And then at some point out in the not too distant future, we\\'ll see a shift back toward the development cycle where they\\'ve learned a lot from how these are used, what they\\'re capable of, and they start turning on and developing their own features to really see the value of how do I transform my private and important\\\\\\\\n\\\\\\\\nJon Duren (14:52.688)\\\\\\\\nimportant business processes and workflows.\\\\\", \\\\\"Aaron Delp (14:56.5)\\\\\\\\nYeah. And, Drew\\'s, I\\'ll give you a second to add to that, but I\\'ll also just kind of ask this real quickly. when we talk about a Gentig AI and like SharePoint and ServiceNow and some of these other things and being baked into the tools for you as, somebody in the security arena and cybersecurity, does that just make your, your blood run cold? Like what\\'s your, what\\'s your thoughts on opening that can of worms, if you will.\\\\\\\\n\\\\\\\\nDruce (15:23.314)\\\\\\\\nOh boy. Yeah. So, so first of all, you\\'re like one of the things that, that again makes me, you know, makes me roll my eyes a little bit is when you look at, uh, again, you\\'re one of my pet peeves or people who are throwing out, uh, you know, uh, AI and Gentic AI without really a real use case of what it is that they\\'re trying to do. And I think\\\\\", \\\\\"what we\\'re gonna end up doing, and again, I kind of go back to early days of Microsoft. I go to that well a couple of times here. What I\\'m seeing a lot of people do is recreate the concept of Clippy, if you ever remember Clippy. Yeah, people are trying to figure out how to get the chat thoughts and try to be like, okay, I want it to take action. The problem...\\\\\\\\n\\\\\\\\nAaron Delp (16:06.593)\\\\\\\\nyeah, yeah.\\\\\\\\n\\\\\\\\nDruce (16:17.842)\\\\\\\\nproblem that I\\'m seeing for the most part is that AI as a technology is very data hungry. It needs data to be trained off of. in that respect, the types of people that John actually interacts with daily are the types of people who have large databases of interesting information. And there\\'s actually really good stuff to be able to do with it. When you talk to a lot of...\\\\\", \\\\\"cybersecurity startups, you know, they\\'ve got a database of, you know, of threats that might\\'ve happened, but it\\'s kind of hard to like, it\\'s not really a statistically significant enough data set that you can actually even present queries to it and have it come back with anything of any sort of relevance or, you know, or, you know, anything really useful. The concept is there, but it\\'s, it\\'s a matter of, you know, again, this is why I see a lot of these, a lot of these startups are trying to\\\\\\\\n \\\\\\\\ntrying to push this as being their predominant thrust. If they don\\'t have the data to back it up, then they\\'re creating that they have a really interesting algorithm and the algorithm will be useful when they get data and they\\'ll get data when they get customers. The customer doesn\\'t want to buy until it\\'s showing value and they can\\'t provide value until you kind of have the circular logic. So where I see this really becoming\\\\\\\\n\\\\\\\\nAaron Delp (17:36.928)\\\\\\\\nIt\\'s quite a circle. Yes.\\\\\", \\\\\"Druce (17:44.966)\\\\\\\\nvery useful. There\\'s a I\\'m not expecting even the people out there, even if they\\'re in the cybersecurity community to know the acronym, but there\\'s a concept out there called CTEM, C-T-E-M, which is continuous threat exposure management, which really isn\\'t that new. Really what the concept is, is you go in, you\\'re trying to establish some sort of a threat exposure. And then when you get exposed, you\\\\\\\\n\\\\\\\\nyou try to close the circle and figure out, okay, so what could I have done to fix this? And let me institute the policies to prevent it from happening in the first place. So that circular thing, that rarely happens because in a cybersecurity organization, again, they\\'re very resource constrained. So they\\'re usually playing whack-a-mole with some of these things. So they\\'ll go get out to a point where they get to correct the problem, but never get to the point where they can actually iterate.\\\\\", \\\\\"and solve the problem. This is where I think there\\'s a real opportunity. And again, you look at any, it doesn\\'t have to be cybersecurity. You look at any organization or any industry that is resource constrained from a manpower standpoint. And that\\'s where AI is gonna end up shining. It\\'s gonna make those people that you have.\\\\\\\\n\\\\\\\\njust more effective. if they have time to actually be able to chase some of this stuff down, they\\'re going to be able to do what they need to do. But in the meantime right now, as I said, I was speaking, I don\\'t want to out a very, very famous market research company I was speaking to today. And you may be able to figure out who that is.\\\\\\\\n\\\\\\\\nAaron Delp (19:31.2)\\\\\\\\nSure.\\\\\", \\\\\"Druce (19:36.37)\\\\\\\\nput into, actually they basically said, we\\'re gonna take all AI and we\\'re gonna throw it into one of two categories. There\\'s the useful stuff and then there\\'s the cute stuff. And there\\'s a whole lot of cute, but there\\'s not really a whole lot of things where you\\'re like, okay, so it\\'s really cool that you have this chat bot that you can ask questions about, is that really saving me time? And this is...\\\\\\\\n\\\\\\\\nThis is again the same arguments that you have if you get into any sort of IT organization where they feel like I can write a Python script way faster than I can go through a UI and drag and drop all these things into. like, just let me automate this with the script as opposed to anything else. It\\'s the same concept. When you try to automate something but the automation is actually taking you longer, that\\'s where it\\'s going to fall flat.\\\\\\\\n\\\\\\\\nAaron Delp (20:29.908)\\\\\\\\nYeah, yeah, no.\\\\\", \\\\\"Druce (20:30.126)\\\\\\\\nIf it\\'s really helping you save time, that\\'s where it\\'s going to be, where it\\'s going to shine.\\\\\\\\n\\\\\\\\nAaron Delp (20:34.772)\\\\\\\\nNo, I love that. Yeah.\\\\\\\\n\\\\\\\\nJon Duren (20:34.934)\\\\\\\\nOkay, new business idea. The three of us are going to create the Whac-A-Mole LLM.\\\\\\\\n\\\\\\\\nAaron Delp (20:39.508)\\\\\\\\nYes, completely, completely. I love that. So, so let\\'s talk about velocity. And the reason why I say that is because, I mean, it\\'s funny, it\\'s this, this thing, I think in our industry, everything just keeps moving faster and faster and faster.\\\\\\\\n\\\\\\\\nDruce (20:39.602)\\\\\\\\nThey\\'ll go with my AI based Rolodex.\\\\\\\\n\\\\\\\\nJon Duren (20:45.653)\\\\\\\\nThat\\'s right.\\\\\\\\n\\\\\\\\nDruce (20:48.572)\\\\\\\\nThat\\'s an inside joke.\\\\\", \\\\\"Aaron Delp (21:04.332)\\\\\\\\nAnd part of that is like I go back to like, like Kubernetes and containers and Kubernetes started, you know, when they started releasing, you know, three and four times a year, everyone in the industry was like, whoa, whoa, whoa, whoa, that\\'s too fast. Right. Like because most organizations aren\\'t going to upgrade their infrastructure that many times a year or like Nvidia with, you know, all the GPUs and like, you know, they\\'re being accused now, like the roadmap is too fast. And, you know, I have these big\\\\\\\\n \\\\\\\\npurchases and I got to get them off my books kind of thing, right? And so you have like ROI is start isn\\'t measured in three to five years anymore. ROI is especially for AI projects is like 12 months, you 24 months kind of thing. And then organizations, it\\'s like, how do I absorb all the changes and LLMs, you know, coming? And so do you first of all, how do you have those conversations with customers when\\\\\", \\\\\"because it almost can lead to almost like analysis paralysis of like, Hey, I\\'m not going to do this now because there\\'s this next thing great thing coming out next month. Right? How do you, how do you get folks over that?\\\\\\\\n\\\\\\\\nJon Duren (22:12.184)\\\\\\\\nYou know, I think the best answer to that is focusing entirely on their use case. Stop worrying about the underlying technology. Matter of fact, in the briefings we talk about from worldwide, we encourage customers to focus on and understand that while they\\'re designing, things will be changing so rapidly underneath them. So focus on a development methodology that\\'s very agile. I know that has its own meaning, but\\\\\", \\\\\"understand and plan for that change. But again, if you focus on the outcome, if you focus on the use case, what they\\'re trying to achieve rather than the technology itself, a lot of those problems will solve themselves along the way. And I actually don\\'t discourage anyone from slowing down. This is one of those trains you must be on. If you get left behind in this one, the business advantage that your competitors are going to have will be insurmountable.\\\\\\\\n\\\\\\\\nIt\\'s a matter of we\\'re all learning. I\\'ll say lastly, wrap that we\\'re all still in the experiment and experimental phase. AI is evolving so fast and we are at the youngest stages of what is capable of, especially generative AI. Understand that, realize it, plan it into the way you build and develop, but keep moving as fast as you can.\\\\\\\\n\\\\\\\\nAaron Delp (23:35.292)\\\\\\\\nDo you have anything to add to that?\\\\\", \\\\\"Druce (23:37.53)\\\\\\\\nNo, mean, like I\\'ll just kind of double down on what he said that, know, like it\\'s all, it really all ultimately is about the use case. You know, like if you start with what problem am I trying to solve? And that problem can\\'t be, I\\'d really like to play with AI. If you start from that, then you\\'re not gonna be able to, you\\'re not gonna go wrong. I mean, and.\\\\\\\\n\\\\\\\\nJon Duren (23:56.302)\\\\\\\\ncute.\\\\\\\\n\\\\\\\\nDruce (24:02.142)\\\\\\\\nIf you\\'re worried that people are going to be that there\\'s going to be something new next month, guess what? You\\'re absolutely right. mean, we\\'re going to sit around on a podcast like this 12 months from now and crack up about how incredibly pathetic chat GPT 4.5 was. It\\'s it\\'s things are iterating that that rapidly and you\\\\\", \\\\\"Next year when you\\'re doing this, you might be able to use some of that new technology to make what you\\'re doing better. But don\\'t wait for the next thing because that\\'s what ends up getting you. That\\'s what your competitors aren\\'t waiting. So you shouldn\\'t be either.\\\\\\\\n\\\\\\\\nAaron Delp (24:45.226)\\\\\\\\nSure, no, I...\\\\\\\\n\\\\\\\\nJon Duren (24:45.422)\\\\\\\\nI want to tie that together. One quick note. This is also a key element of the Startup Lantern podcast that we talk about is when you\\'ve got an idea, strike while the iron is hot. Don\\'t wait. Things will change. But every moment you delay gives someone else an opportunity to pass you up.\\\\\", \\\\\"Aaron Delp (25:05.138)\\\\\\\\nLove that. Love that. I think that\\'s a great place to close out on john. So john juice, thank you very much for your time. But before we we part here, tell everyone, first of all, where can they find your podcast? But by the way, link is in the show notes. But also, if anyone is interested in the things we talked about today, what\\'s the best way to kind of get started on their AI journey outside of the podcast as well?\\\\\\\\n\\\\\\\\nDruce (25:32.018)\\\\\\\\nSo again, our podcasts, primarily are pushing this out on YouTube and LinkedIn. Link is in the description. And I will let John actually answer the question about how to get started.\\\\\", \\\\\"Jon Duren (25:46.126)\\\\\\\\nWell, if you\\'re looking for AI help to get a company started, Drus and I are happy to have those conversations around the startup lantern and the concepts there. If you\\'re just looking for help to get to move an enterprise business along, worldwide technology can help. We\\'ve got capabilities, briefings to help everyone at any level or any maturity level across that AI journey and would love to help.\\\\\\\\n \\\\\\\\nAaron Delp (26:13.78)\\\\\\\\nFantastic. Well, gentlemen, thank you both. That\\'s the time we have for today. So everyone out there just wanted to say thank you very much for listening. And as always, if you have feedback, show at the cloudcast.net or wherever you get your podcast, if you could leave us a review as well. We are out of time for this week, but we certainly thank you for your time and we look forward to hearing from everyone next week.\\\\\"]\", \"[\\\\\"Brian Gracely (00:03.694)\\\\\\\\nThree, two, one. Good morning, good evening, wherever you are. Welcome back to the Cloudcast. We are coming to you live from the Master of Cloudcast studios here in Raleigh, North Carolina. Hope everybody is doing well. May is upon us. We are now into the fifth month of the year. Wow, it\\'s amazing how fast time flies. Hope everybody\\'s doing well. Had an interesting conversation with a friend this week, another friend who works in the technology industry, has a chance to engage with a lot of different companies and so forth.\\\\\", \\\\\"talking to him, we were talking about just, you know, how work was going and so forth. And he basically told me that his company had recently decided that they were kind of shifting their focus from being a very, I\\'ll call it sort of AI conservative viewpoint, right? Meaning, not that they didn\\'t think it had a role, but they were being very conservative, especially for internal workers, knowledge workers, and so forth, being able to use AI tools. So they had sort of put a thing in place where\\\\\", \\\\\"any new tool that was being requested to you. So first and foremost, you weren\\'t just allowed to kind of go out and do whatever you want. couldn\\'t just use a copilot or a Gemini or a chat GBT or a Claude or whatever. You if you\\'re doing anything that was related to business, you kind of had to go through this committee. You had to submit some forms, you had to kind of fill out some things. You had to sort of prove that you weren\\'t going to, I don\\'t want to say maliciously use it, but make sure that data wasn\\'t leaked out there.\\\\\\\\n\\\\\\\\nAnyways, it was just sort of a conservative first approach to how to use it out of concern that there just weren\\'t the right sort of guardrails in place or the right data loss prevention or whatever it might be. And he said the company kind of had a change of heart, if you will, or a change of perspective, and kind of went 180 degrees and basically said, hey, are opening up the policies, we are opening up\\\\\", \\\\\"to let people begin to use a number of these tools. We\\'re going to begin to make them available. They\\'re part of some of the bundles that we use for internal productivity, whether it was Microsoft or Google, it doesn\\'t really matter. And sort of sort of unlock this. And he said, part of it was, there wasn\\'t necessarily a reason given as to why they took this shift in perspective, but his perspective was, or his assumption was,\\\\\", \\\\\"Brian Gracely (02:23.95)\\\\\\\\nyou know, they were, they were hearing from other colleagues. People were, uh, you know, talking about things and it just basically, I don\\'t want to say it was sort of a peer pressure thing, but it was sort of a, Hey, you know, we, you know, we have, you know, company goals. have productivity goals. have profitability goals. Um, we are talking to our company, you know, our, our customers and so forth, and we\\'re hearing things being used and we really just kind of don\\'t want to be, feel like we\\'re being left behind. And I think, I think the consensus that he maybe got was,\\\\\", \\\\\"they were being left behind in that they just weren\\'t adopting things fast enough and they weren\\'t building a learning curve fast enough to figure out what wasn\\'t there. They were just basically taking the approach of like, hey, we already know what\\'s best, right? And maybe there was other variations to that, it was sort of, they were gonna learn through conservative approaches and they were watching the rest of the world begin to adopt these things again.\\\\\", \\\\\"may be very, very positive, may be negative, may be lots of things. But the rest of the world was sort of learning at a much faster pace, adopting at a much faster pace, and beginning to figure out what you could do with these tools at a much faster pace. And I think some of that is sort of playing itself out. We look at the numbers, at least for this last quarter, from both Microsoft and Alphabet or Google. Both announced very good numbers for the quarter. Microsoft was up 35%. I think Google was up 28%. We dig into that.\\\\\\\\n \\\\\\\\nin the Cloud News of the Month that\\'ll come out here next week. Brandon and Aaron and I dig into that in more depth. But I think we\\'re seeing sort of the earliest on-ramps, low-hanging fruit, if you will, kind of being focused around knowledge workers and what some of this generative AI stuff can do. And it was interesting having this discussion with my friend, kind of digging into what was he beginning to do, how was he beginning to use it.\\\\\", \\\\\"I think what his take on things, and again, I think I\\'m seeing similar things as I talk to a lot of people, seeing similar things. The first thing that you kind of have to get over is just figuring out what the tools can do. So what tools are available to me, what the tools can do, and especially if you\\'ve been sort of in a situation where it felt like you weren\\'t permitted to use the tools or you were concerned about, I\\'d like to, but I also don\\'t want to lose my job. I don\\'t want to do something dumb.\\\\\", \\\\\"Brian Gracely (04:50.958)\\\\\\\\nthe first thing sort of becomes, you know, what\\'s out there, what\\'s available to me, right? So it\\'s the path of exploration, right? And this is where you start, you know, everything from just, you know, opening up a various set of tools, kind of seeing what\\'s there, what seems obvious, right? So this gets into some pretty interesting discussions of sort of, you user experience, like how easy is it once you\\'re in a tool to do things? In most cases, for a lot of these tools, the default is just sort of a...\\\\\", \\\\\"a chat interface, right? It\\'s sort of a chat bot, chat GPT type of experience. But you start digging into things, you know, where can I do customizations? Where can I bring my own data? Where can I sort of keep things that I want to reuse multiple times, right? So there\\'s very much a set of exploration going on. I think the second thing that you start to figure out how to do is you go, okay, that\\'s what I could figure out myself. And you begin to do this sort of a secondary type of exploration, which is\\\\\", \\\\\"You\\'re either going to go out to forums like Reddit or YouTube or you know, just Google searches or you search or whatever you\\'re doing to sort of figure out like hey Are there are there any best practices like what are suggestions people have for how to be productive doing? Whatever your sort of day-to-day tasks are are you seeing people do kind of creative ways of doing things with them, right? So it\\'s sort of a a secondary Exploration sort of you know looking at broader communities kind of what\\'s out there in the world. What have people learned so far?\\\\\", \\\\\"And then I think the next thing you start doing is you really start beginning to kind of apply it to stuff, right? So take something you\\'re working on, whether it\\'s a document, a set of research, data collection, analysis, summarization of something, whatever those things might be, and just kind of plopping some things in there and seeing what comes out of it and sort of doing a self-evaluation of, for example, let\\'s say you took a document that you had written about whatever.\\\\\\\\n\\\\\\\\nand sort of drop it in there and see what the system comes back with. So say, hey, could you enhance this? Could you shorten it? Could you make it more crisp or more focused or whatever you can kind of do to play around with it? And what you start to realize is there\\'s sort of a couple of things that go through your head, at least what I\\'ve seen and in talking to people with what they\\'ve seen. You kind of go through a little bit of different kind of intellectual processes, emotional sort of processes of\\\\\", \\\\\"Brian Gracely (07:15.926)\\\\\\\\nOK, that\\'s another way of looking at it is that it\\'s interesting. First and foremost, it\\'s like having a set of editors available to you. It\\'s nice to be able to kind of quickly go, hey, try this variation. So punch it up. Make it more attention grabbing. give it more energy. Be more technical, whatever it might be. And it\\'s nice just from that perspective to be able to essentially\\\\\", \\\\\"you know, build a bunch of variations, essentially, you know, go back to that sort of first principle thing that we talked about with cloud computing a decade ago, be able to do a lot of experimentation and to be able to do it very fast, very inexpensively. and, and then be able to pick and choose what you like out of things, be able to go, Hey, I like a lot of this. but you know, this section here doesn\\'t necessarily work for me or whatever it might be. So, you know, I think the third thing that sort of goes along. you know, you had sort of.\\\\\\\\n \\\\\\\\ninitial exploration, you had sort of community exploration. Third piece I sort of find is experimentation, right? And beginning to understand what this new opportunity with experimentation looks like in terms of variety, in terms of just having optionality to what you do, you know, to be able to quickly see what\\'s there and to mix and match the things and see where, you know, things come together. So I think that\\'s all very, very interesting.\\\\\", \\\\\"The next phase that I\\'ve sort of found and I\\'ve found in talking to people is you kind of go through this somewhat emotional or or You just sort of decision-making process of you know, is that something that I want to make part of my normal workflows? Or you know, do you you know, do you kind of go through that stage where you feel like this isn\\'t this isn\\'t as good as what I do right or and I\\'ve seen this in multiple cases, right I\\'ve seen You know well-known\\\\\\\\n\\\\\\\\nwriters and analysts and other people go well, you know, I use it from time to time to start me with some stuff, but there\\'s kind of this ego that gets in the way. And again, maybe it\\'s a good ego, maybe it\\'s bad ego, that kind of says, well, but I wouldn\\'t want to just use it as it is, right? So it\\'s essentially the, the equivalent of kind of saying it\\'s there, but it\\'s not as good as what I would do, right? Or it\\'s just not what I would do. And\\\\\", \\\\\"Brian Gracely (09:37.762)\\\\\\\\nYou know, again, I see there\\'s going to be situations in which that\\'s a psychological decision, an emotional decision to make. you know, if the thing that you work on feels like it\\'s being displaced or even bypassed, you know, that can be a challenging thing to sort of deal with. but I do think everybody\\'s going to go through that, that sort of, process and they may go through it multiple times and they may have to figure out like, Hey,\\\\\\\\n\\\\\\\\nWhat does a new normal look like? Do I want to adopt this as a new normal? I think that\\'s going to be a big part of this evolution is you\\'re going to find different people. And what\\'s going to be interesting, and I\\'ve seen this even in my own case, you get projects in which you have team projects, for example. And some people are going to be much more eager and willing to adopt it or want to make it part of their workflow, while others in the team may\\\\\", \\\\\"you know, be more hesitant to deal with it. And it\\'ll be interesting to sort of watch how team dynamics work when, you know, just like anything, you know, you\\'ve got certain people pushing a direction, a, a, an opinion on something and you\\'ve got others that are saying, no, no, no, I\\'m not, I\\'m not ready to adopt that. I, I I\\'m uncomfortable with that for whatever reason, or I don\\'t think it\\'s the right way to go. I don\\'t think it\\'s as good as what we do or whatever those things might be.\\\\\\\\n\\\\\\\\nSo it\\'s me interesting sort of watch those team dynamics shake themselves out The the next thing that I\\'ve sort of have found is And I think there\\'s I think there\\'s a lot to be figured out in this place is as some of these tools come along and again as you\\'re doing projects that involve multiple people which often cases is you know is the case whether It\\'s you\\'re working on a project with a bunch of people and the process the progress is being made\\\\\", \\\\\"consecutively with a bunch of people or if you are working on something and then the byproduct of what you do becomes part of something that\\'s for a group becomes bigger becomes, you know, part of something more. I found at least in dealing with some of the tools and again, I\\'ve heard this from other people and I\\'d be very curious to the audience, you know, feel free to shoot us some of your feedback or some of your, you know, your learnings from this, you know, show at the cloudcast.net or hit us up on social media.\\\\\", \\\\\"Brian Gracely (12:01.986)\\\\\\\\nI do feel like the sharing aspects of it are still lacking, right? And I say that in the context of we have all sorts of tools these days to share stuff, whether it\\'s Slack or file sharing or Google Drive or whatever it might be. mean, sharing in the context of not sharing on Instagram, like social media sort of sharing, but mean, sharing in the context of here\\'s information.\\\\\\\\n \\\\\\\\nHere\\'s a collection of data. Here\\'s an output whatever it might be that you want to share with a group and it might not just be a link it might be Sharing of what was the process you took to get to there, right? You know how much of it was things that you created how much of it was 12 different experiments using some of the AI tools It might be hey, where did you pull data sources from right? So for example, you know, one of the things that I\\'ve been working on is you know a set of presentations\\\\\", \\\\\"for a series of events. some of them I will be actively involved with and others I\\'m doing on behalf of some other people or some other groups. And you want to try and put it in their voice. And if you\\'re doing it by yourself, that can be sort of hard unless you spend a lot of time with those people and those individuals, or you really understand their specific view of the world. for example, if they had a bunch of previous work that they\\'d done that you could take, collect,\\\\\", \\\\\"have the AI tool sort of review and look at and go, okay, that\\'s the tone of this person. That\\'s the language that they tend to use, the way that they tend to, you know, their turn of phrase, their sort of speech characteristics. You could build sort of a profile of that, right? We see that with things like Chat GPT where you can do custom GPTs or Google has something called Gems. A lot of these tools are allowing you to sort of build your own data collection thing or a thing that will sort of speak in the voice of something.\\\\\\\\n\\\\\\\\nBut I find that the process of then taking that and sharing that still is more cumbersome or doesn\\'t necessarily exist in repetitive ways yet. So I think there\\'s a big opportunity both in terms of how those tools are built and customized and taught and learned and made smarter, but also how\\\\\", \\\\\"Brian Gracely (14:27.382)\\\\\\\\nthat whole sharing goes on there, right? Like how do we share best practices that one or two people have learned so that other people can learn them really quickly? Not just here\\'s a set of data or here\\'s a link to an output of something, but what was the process for doing that? Right? I feel like, you know, as we think about AI as a productivity type of thing, there are opportunities for these tools or something, some sort of collection mechanism to help us with best practices, with sort of\\\\\", \\\\\"identifying what the process was for something to get created so that other people, if they\\'re new onboarded to the job or they\\'re changing roles or they\\'re now working with a team, they can very quickly kind of get up to speed on doing that. And I do feel like there\\'s, you know, the other piece that feels like it\\'s missing, not only in the sharing piece, but, you know, in the data piece, if you will, right? The ability, and this feels like a data lake or a big data, you 5.0 sort of problem.\\\\\\\\n\\\\\\\\nis we have all these activities to build gigantic repositories of data. And in some cases, they are doing tagging and auto-tagging and all sorts of things to identify what the information is. But it does still feel like it\\'s very difficult to, even for your own information, be able to just say, hey, I\\'ll give a really simple example. Hey, go into all of the presentations that I\\'ve built over the last three or four years.\\\\\", \\\\\"and allow me to quickly just search for things, right? Whether it\\'s an image or a set of keywords or a set of concepts or whatever that might be, you know, we\\'re, we, we still have issues of, you know, formatting of what data, you know, is in certain formats. How do I go looking through it? How do I tell it, you know, you know, kind of in natural language, Hey, go out and find me all of the, you know, presentations that I\\'ve given on innovation, for example.\\\\\", \\\\\"you know, and innovation may not necessarily be the topic, but you might be able to find ways to go like this is, you know, these are the new things versus things that are older and so forth. So it does feel like that, you know, those two things more than anything, still feel like big gaps in this in both in terms of how things are shared, how best practices are created, you know, how those can be distributed across the company or within a team, and as well as, you know, sort of the\\\\\\\\n \\\\\\\\nBrian Gracely (16:54.604)\\\\\", \\\\\"the bigger picture with, you know, how data is collected, how it\\'s tagged, how it\\'s identified, how it can be shared, you know, how it can be embedded into something. And then that embedding then gets shared along to something else. You know, so it does feel like there\\'s a lot of opportunity here, but it is, it is very interesting, I guess, coming back to sort of the original thing I talked about, it is interesting to watch the companies that kind of unleash this capability to their\\\\\", \\\\\"to their organization without too many restrictions, kind of expecting people to have a certain amount of awareness of what\\'s going on. And I\\'m sure that\\'s going to have certain problems too. People are going to make mistakes and things are going to maybe get leaked out or some incorrect answer is going to be provided somewhere. mean, people make mistakes, people made mistakes before versus the companies who actively try and sort of focus on\\\\\\\\n\\\\\\\\nyou know, kind of a conservative approach first, a safety first approach. And again, there\\'s nothing wrong with that. I just think it\\'s gonna be very interesting to watch, you know, as case studies and industry trends and, you know, market share and market differentiation, begin to sort of shake out and to be able to identify within any given market or within a given sector or within a given region, you know, how much does a willingness and a kind of an aggressive\\\\\", \\\\\"approach to adopting AI start to have material impacts. You know, how can people measure it? How can people identify it? How can they measure it? How can they incentivize people to adopt it when they start to begin to figure out best practices? How do companies share those best practices, right? Do people sort of hoard them as is often the case or do people, you know, become pretty good team players and share them? I think there\\'s a lot of\\\\\\\\n\\\\\\\\ninteresting learnings are going to happen over the next year or so, because I think we\\'re already beginning to see, you know, we\\'re beginning to see the numbers start to play out. We\\'re starting to see more companies recognize what\\'s possible. And so, yeah, I think it\\'ll be fascinating. I would love to hear from anybody. And again, you can send them anonymously to us. We\\'re not necessarily looking to kind of, you know, find out things about your company, but we\\'d love to sort of hear, you know, your best practices, your\\\\\", \\\\\"Brian Gracely (19:16.47)\\\\\\\\nexperiences, your learning curves, how you\\'re getting over some of those challenges. Shoot us a note, show at thecloudcast.net. We\\'d love to do that. Or if you want to talk about if you\\'ve been doing it for a while, we\\'d love to highlight that on the show as well. So very, very interesting time. Again, interesting to catch up with colleagues and friends, both in your industry as well as across different industries to see how this is impacting them. And I do feel like\\\\\\\\n\\\\\\\\nknow, while there\\'s been a ton of headlines about the largest models and, you know, billion trillion dollar valuations and all those sorts of things. think, I think there\\'s, there\\'s a lot to be discovered in the low hanging fruit, the early on ramps, the simple on ramps, you know, the, simple tools versus the proliferation of, of tons of tools, as to, know, how people are able to use this for, you know, successful,\\\\\", \\\\\"Deployments productivity enhancing deployments and all those sorts of things. So anyways, hope everybody\\'s doing well. Hope you\\'re You know, I hope your first quarter and first third of the year is been going well Excited for May for those of you that watch the Kentucky Derby kind of Like yesterday, but hopefully everybody\\'s doing well. Thanks for listening lots of good shows coming up Thank you for feedback on the shows and thank you for telling a friend. We appreciate helping us grow the show So with that, I\\'m wrap it up and talk to you next week\\\\\"]\", \"[\\\\\"Brian Gracely (00:03.276)\\\\\\\\nAnd we\\'re back. And as I mentioned at the top of the show, I want to dive a little bit into some things I\\'ve been reading, some discussions I\\'ve had recently with various companies around, you know, kind of their deployments around AI, the things they\\'ve learned in the early, you know, early months and maybe year that they\\'ve been deploying some stuff and some of the sort of challenges and psychology that they\\'re now starting to deal with as they become a little more familiar with the technology, familiar with usage patterns, familiar with how they\\'re justifying cost, all those types of things.\\\\\", \\\\\"And I thought there was a couple of interesting things that were worth kind of talking about today. And I\\'ll begin by sort of saying, you know, when we, when we think about, when we talked about most AI usages, most AI applications, especially as we\\'ve sort of put them in the context of, you know, sort of enterprise business usage, not necessarily like just making an avatar for your social media or, you know, making a, you know, a fake video so that you can, you know, troll people on the internet, whatever that might be. but a lot of times, you know, the, the\\\\\", \\\\\"The way if you were to sort of categorize them or the things that you\\'ve seen from successes kind of fall into either kind of human augmentation, right? We\\'re trying to help people be more efficient with what they do, relieve them of doing some of the kind of low value things, but allowing them to spend more time on stuff. So there\\'s still very much people in the equation. And there\\'s lots of examples of that. Developer Copilot\\'s a great example of that. And then there\\'s sort of another category of them that would be sort of human replacement.\\\\\", \\\\\"Right? So the goal is we have a task that if they sort of really mapped out what the task was, it could very much just be kind of completely automated. Right? In this case, we happen to be using AI technology to automate it. We hear examples of this of like, hey, we\\'ve got a staff of people who do nothing but look at changes to legal documents, for example, or something related to their industry. Maybe it\\'s changes to building codes or something. And they come out.\\\\\\\\n\\\\\\\\nwith a bunch of documents, there are hundreds of pages, they could now feed those into some sort of LLM. The LLM could summarize the changes without really having a human in the loop, So we see some of those types of things as well, and those fall more into the sort of human replacement category in terms of the task. I\\'ll start with, if we think about it, technology has either augmented, shifted, or replaced human tasks for a while.\\\\\", \\\\\"Brian Gracely (02:30.21)\\\\\\\\nRight, so this isn\\'t necessarily anything new, right? Every one of us experienced this, maybe if you go to any sort of retail store and they allow you to now check out, do self-service checkout, right? You\\'re able to bring your groceries and run it through the scanner and bag it and all that stuff, as opposed to going through the checkout person, right? That\\'s a simple thing. We\\'ve seen, you know, things like over time, farming equipment has become, you know, the technology around farming equipment has become more powerful, more automated.\\\\\", \\\\\"the amount of work that any single person could do with a you know set of tractors or whatever is far more than it used to be with You know many many people with you know large labor is animals, you know mules or oxen or whatever it might be So, you know, we\\'ve seen this for a long long time in lots of different fields. It\\'s not you specific to anything You know, we\\'ve seen the conversation that people have of you know within IT. You should automate more tasks maybe you\\'re using a an ansible or a terraform or something like that and\\\\\", \\\\\"You know, again, same sort of things. could be replacement of task. could be augmentation of task. It\\'s always some combination of those things. so this bringing AI into it isn\\'t a new conversation for any industry, let alone the technology industry. But I think what we\\'re seeing is a little bit more of just kind of the acceleration of what\\'s possible if the technology is applied in the right place, right?\\\\\\\\n \\\\\\\\nAnd we\\'ve also seen for a long time that management or owners of businesses have always tried to replace workers with technology where possible. Because again, you could argue lots of reasons for doing it, but at the most bottom line reasons, when you\\'ve got sort of technology as opposed to people, the technology doesn\\'t tend to get sick. You don\\'t have to pay it over time. You don\\'t have to pay it for vacation. You don\\'t necessarily have to pay things like\\\\\", \\\\\"taxes, social security taxes, other sort of safety net taxes, insurance, all those sort of things. Yes, you do have to maintain the equipment. It does have bugs and technology problems and all that kind of stuff. But the perception is the more you could leverage technology as opposed to humans, if you were just looking at it from a bottom line perspective, this has been a thing for a long, time. Even technology doesn\\'t necessarily introduce this. We\\'ve seen this in\\\\\", \\\\\"Brian Gracely (04:49.824)\\\\\\\\nin factories, know, robotics in factories, building cars, all sorts of stuff. Right. So again, this isn\\'t specific to, you know, new technology, i.e. just AI, right. We\\'ve seen this for decades and decades and centuries and centuries. So I think what I\\'m kind of getting at and what I\\'ve seen lately is a couple of interesting things. So I had a conversation with a couple of different companies out at events over the last couple of weeks, and one of them was sort of interesting. This was a company who had\\\\\\\\n\\\\\\\\nhas rolled out a decent amount of AI. In fact, they highlight it on their website and other types of things. So really good for kind of showcasing what they\\'ve done, showcasing what technology they\\'ve used, regulated industry stuff. So allows their peers to sort of see what\\'s going on there and so forth. And the conversation sort of like this. They had rolled out, like I said, a set of different technologies, some sort of chat bots, so some...\\\\\", \\\\\"human engagement stuff, some internal facing stuff, some external facing stuff, some stuff to augment software developers or operations people, some stuff to try and classify content and a whole bunch of things, your kind of sweet spot bread and butter, low hanging fruit, gen AI stuff. And what was interesting was as we were talking about things and where they were going and some of the stuff that they were looking to do, they brought up an interesting question. said, hey, we\\\\\\\\n\\\\\\\\nwe have rolled out a lot of stuff. And one of the metrics of success that we\\'ve used is adoption rate. So for example, in one of the areas they had rolled it out to X number of thousands of people. And one of the measurements they were using was what was the adoption rate either on a daily basis or weekly basis again, it depended on the task and so forth. And, and so they were seeing, you know, relatively high adoption rates, I think it was in them, you know, plus 60%, maybe it was closer to 70 or 80%. And\\\\\", \\\\\"they were using that metric. And then what they were running into was so on one hand, they felt like they had gone through all the things that you normally should go through in terms of, is this viable technology? Have we put certain things in place to be able to sort of track it from an accuracy perspective, hallucinations? Are we aware of who\\'s using it? And are we putting certain things in place to make sure that the wrong information doesn\\'t get in the system? So they.\\\\\", \\\\\"Brian Gracely (07:11.618)\\\\\\\\nThey\\'d kind of gone through, you know, we think we\\'ve done a lot of the right things. Again, still early days recognizing that the things can get better. What was interesting was their initial measurement was what was going to be the adoption rate. And I think the reason for that and what they sort of started telling me was they had sort of been told by the people who provided the technology to them. This wasn\\'t sort of all homegrown. They had used a vendor and an outside party to sort of drive some of this stuff.\\\\\", \\\\\"was that they had said, the success rate you\\'re going to see is something like 50 to 60 % greater output as a whole. So augmenting the people that are going to be using this technology by 50%, 60%. And this was based on what the provider had used in whatever studies they had measured. Then again, it\\'s always, your mileage may vary, your use case may vary, and so forth.\\\\\\\\n \\\\\\\\nBut the reason this sort of came up was they felt like, okay, we use that number to then build a business case for adoption of what they wanted to do. And part of the business case was also reaching this level of adoption in terms of volume, right? So like I said, the 60 to 80 % usage. And what they sort of came back with was they said, well, what we\\'re seeing is we\\'re not necessarily seeing\\\\\", \\\\\"that much additional productivity, right? And they gave me a different number. just assume it\\'s less than the 60 to 80 % or 50 something percent greater productivity. Maybe it was 20 % or 15 % or 30%, whatever it was, it wasn\\'t that level. And what was interesting to me was the conversation wasn\\'t about how do you think we could get the level of additional efficiency up? They said,\\\\\\\\n\\\\\\\\nwe\\'re now starting to be asked by senior management, how do we then, how do we go from like 50 or 60, know, whatever they were at, let\\'s just call it 30 % just so we can talk in the same thing, right? Like 30 % greater efficiency to replacing the people. And, you know, as we were talking about it, it didn\\'t feel like a radical conversation, right? This wasn\\'t an organization that was, or, you know, the couple of organizations we talked about, they weren\\'t, you know, a company that was like,\\\\\", \\\\\"Brian Gracely (09:40.042)\\\\\\\\nMassively venture funded and so they felt this huge pressure because they had a huge valuation This was a very stable company a well-established company had been in place for a very long time but it was very interesting that they were sort of jumping to this thing of I Didn\\'t I didn\\'t get to where I was initially and I want these the technology providers To help me get from let\\'s just call it that that 25 or 30 percent additional efficiency to a hundred percent\\\\\\\\n\\\\\\\\nwhen the initial number that they had built their business around was like 50%. And I thought it was sort of fascinating to sort of hear the logic behind this. And I think the reason I bring this sort of stuff up is, and I\\'ll kind of walk through what we then talked about was, I think there is potentially a very growing feeling that if you\\'re doing this sort of part way, you\\'re not gonna get there.\\\\\", \\\\\"Or you\\'re going to go through a lot of work to not necessarily get there and you need to set your goals higher. And I\\'m not necessarily saying that\\'s the right way of doing it. I\\'m simply saying, I\\'m starting to get this feeling. And the reason I say this is I feel like so much of what we\\'ve seen in the AI market to date has been kind of the, the narrative of it has been driven by a very small number of companies, very, very large companies, very huge amounts of funding or able to put a lot of money into what they\\'re doing.\\\\\\\\n\\\\\\\\nAnd they\\'re talking about it in the context of enormous, enormous amounts of change in very, very small amounts of time. And I point to things like we hear whoever it is, whether it\\'s OpenAI or Anthropic or one of the leading sort of AI labs saying, hey, we are just around the corner from AGI. Maybe we\\'ve already reached AGI or super AGI.\\\\\", \\\\\"these labs that are saying like, we\\'ve already sort of reached that. We\\'re literally right around the corner from this. And so I think that has sort of accelerated people\\'s perspective on when is this thing going to happen. But then we\\'re also starting to see all these conversations happen again, whether it\\'s the O\\'Reilly group saying, hey, software development will never be the same again, or we\\'re hearing we no longer need software developers. We\\'re already hearing we\\'re not going to need operations because there\\'s going to be these agents.\\\\\", \\\\\"Brian Gracely (12:06.958)\\\\\\\\nWe\\'re hearing over and over again in different industries, like there won\\'t be entry level people. We\\'re seeing certain companies, I think it was either Spotify or Airbnb or somebody this week, their CEO had sent out a notice, a memo, an internal sort of thing saying, we\\'re no longer hiring people until you can prove that you\\'ve exhausted all of your resources using some sort of AI tool to do the thing that that person could do. Hence, you\\'ve proven above and beyond.\\\\\\\\n \\\\\\\\nwhat it can do, what AI can do to then hire another person. And again, whether that\\'s the right thing to do or not the right way to do it, we do tend to see certain trends, certain sort of herd mentality happen in the technology industry. And I think because, especially given what\\'s going on in the economy right now, whether it\\'s bumpy or we\\'re headed down a path of, you\\\\\", \\\\\"recession and all those sort of things that people are talking about right now. People become the sort of fodder in how to fix these things. And so I think it\\'s really interesting just to sort of watch that. We\\'ve seen OpenAI now talk about having these PhD level agents that they\\'re going to charge $20,000 a month to be able to do very high level tasks, which I think is interesting. Like before, everything had sort of been, you this thing can\\\\\\\\n\\\\\\\\ncan help with low level tasks. Now we\\'re starting to see sort of rhetoric about kind of attacking the higher level, high value jobs and so forth. But on the flip side, we\\'re also starting to see companies struggle with this. So I put a couple of links in the show notes there for a couple of articles and the information, which in some cases, the things are published in front of the paywall and behind the paywall. People know how to get around them, but I put links to them.\\\\\", \\\\\"AI, the analysis that Salesforce with their agent force, their new sort of AI technology is really struggling to provide people with sort of replacement types of technology. you know, we talked about this a while ago. You can tell a little bit about where a technology company is sort of placing their expectation of the technology based on how they price it. Right. So for example, most of the Microsoft\\\\\\\\n\\\\\\\\nBrian Gracely (14:31.372)\\\\\\\\nsort of co-pilot types of things are done on a per seat basis. And if you kind of map that out, you would assume, well, if their growth is on a per seat basis, their goal wouldn\\'t be to reduce the number of seats, i.e. the number of people, but more so to get you to pay more per seat. But again, sort of in the augmenting people category of how pricing\\'s laid out. Salesforce, on the other hand, is done not on a per seat basis, which is the way previous sort of Salesforce types of things, know, access to the\\\\\", \\\\\"know, customer records and all that kind of CRM stuff was done per seat. This is now being done on a per task basis. So for example, if you\\'re doing this as a customer service type of agent, it\\'s like $2 per query, right? So every time, you know, one of your customers engages with customer service, it\\'s like two bucks for Salesforce, right? So that is very much intended to be like a replacement type of technology, right? And people can do the math of like, what is a normal customer service agent call, you know, cost and how many\\\\\\\\n\\\\\\\\nInquiries do you have and what\\'s the average number of of inquiries per you know per engagement or all that sort of stuff and you can you can figure out the math but they\\'re apparently sort of struggling with that and So I think it\\'s I think it\\'s gonna be very very interesting to watch the way in which Both the technology companies as well as the Using companies the end user companies are sort of looking at this and I do kind of get this sense that\\\\\", \\\\\"there is beginning to be a little bit of a trend or a little bit of an exploration of how do we make this more replacement oriented. And I think it\\'s a difficult situation. And sort of one of the conversations that we kind of had as I was talking to some of these people is I said, look, in many cases, you\\'re not going to necessarily hear the technology companies. And the more I think about this, maybe this isn\\'t necessarily right. I think you\\'re going to hear\\\\\", \\\\\"a set of technology companies saying, we\\'re here to augment what you do, right? And how much you augment that, how aggressively you augment that is completely up to you. I think you\\'re going to hear a different category of technology providers. And again, this could be consulting companies. This could be companies looking to have huge public valuations because right now they\\'re a private company and they\\'re taking on a ton of venture funding. I think you may hear them.\\\\\\\\n \\\\\\\\nBrian Gracely (16:54.158)\\\\\\\\npushing more and more this idea of sort of replacement because that number one doesn\\'t necessarily have a timeline on it. And two, know, if you\\'re, you know, if you\\'re a business or you\\'re somebody valuing the company like that, that may seem like a greater possibility of, of huge valuation somewhere in the future than it does sort of saying, well, everybody\\'s going to kind of get 20 % better, 15 % better, 10 % better or 40 % better, whatever that might be.\\\\\", \\\\\"So I think it\\'d be very, very interesting to sort of watch that. I think the discussion that we ended up having was, what do you, as the end customer, want from your discussion? not from discussion, what do you want from the goal of whatever your project is? And I think where we kind of netted out, without going into all the detail, was we sort of said, I think you\\'ve got to be very careful in terms of where the message of what the goals are comes from and how fine grain you get to.\\\\\", \\\\\"Right. So for example, we were just sort of talking about like building applications just as a, as a category. Right. And I said, on one hand, you know, if, if you\\'re sort of pushing the idea of, we want our current development team or even, you know, future development team, you know, that are working on things that differentiate your business to continue to be valued within the company. The conversation you\\'re probably going to have is how do we augment them? Right. How do we take you from, from an excellent\\\\\\\\n\\\\\\\\nteam, an excellent developer to do it even better. One who can offload certain tasks, maybe it\\'s writing tests or whatever it might be, documentation to somebody who is able to, in some iteration, in some future iteration, able to spend more time thinking about architecture, thinking about ways in which you can differentiate the business through user experience or whatever it might be.\\\\\", \\\\\"sort of holistically saying, we want to, we want to eliminate the need for software developers in our company, right? Maybe you\\'re thinking, we want to go all low, all low code, we\\'re going to give, you know, business analysts and product managers and salespeople, the ability to just sort of go, hey, whenever I got an idea, I can work with this tool, and it will write some software for me. And my goal out of that is, let\\'s, let\\'s sort of shift.\\\\\\\\n\\\\\\\\nBrian Gracely (19:22.882)\\\\\\\\nmaybe it\\'s shifting, maybe it\\'s replacing those tasks that used to go into the queue that some software developer would build to maintain and we\\'re sort of pushing them out to something else. Or maybe we\\'re just simply pushing them to, you know, some sort of agent in the future, one of these super agents in the future, and they\\'re going to do that. And the reason I kind of put these two side by side is if you\\'re granular in how you\\'re explaining what you\\'re trying to do, you can avoid the problem of like,\\\\\", \\\\\"you know, do we kill morale in across the board when we\\'re really only trying to target certain things? Are we measuring the success of an augmentation or the metrics of an augmentation in the same way that we measure sort of a replacement or shifting type of thing? And this is where we sort of got into, you know, a lot of this really is going to depend on the leadership of the company, what their goals are, how they communicate things, you know, how they are, you know, because this is huge, huge sort of\\\\\", \\\\\"you know, shifting, changing what people do. Right. And we\\'re seeing more and more articles come out about, know, just using the developer use case of, know, what does that challenge mean? What does that new environment look like, depending on what the management push is? Right. And I\\'ll put a link in the show notes. There was very interesting article recently of kind of a company who had kind of gone all in because the leader of the team had said, I\\'m going all in myself. And so think the rest of you should kind of go all in.\\\\\", \\\\\"And the scope of what they did in their day-to-day stuff is just a manager, limited coding, more using the tools for other types of things. Taking that mindset and pushing it down onto the development team was having all sorts of weird, adverse, unexpected kind of behaviors. So anyways, I\\'ll put a link to that in show notes. Again, it\\'s just, again, one example, one data point. But again, all these things I think are starting to...\\\\\\\\n \\\\\\\\nstarting to bubble up a little bit. again, technology in and of itself is sometimes very interesting. It has certain characteristics. But technology always has certain byproducts, if you will, certain ripple effects that happen because of what\\'s going on with the economy. So if the economy is struggling, we tend to look for technology to kind of help us improve the bottom line.\\\\\", \\\\\"Brian Gracely (21:47.93)\\\\\\\\nkind of reduce, we think more in the reduction or elimination sort of mindset. When things are going well, and we\\'ve seen this with companies growing and VC funding, we tend to think in the innovation and growth sort of mindset. So the technology is never sort of in and of itself in a vacuum. So with that, I would love to kind of hear feedback from folks. I try and use a lot of these weekend perspectives as both.\\\\\\\\n\\\\\\\\nyou know, kind of things that I\\'m hearing out in the marketplace. But, you know, I\\'d love for them to be, you know, kind of feedback mechanisms from you. Like, what are, what are you hearing in your organizations? As you talk to people across the marketplace, across the industry, at different events or different, you know, meetups and community things and so forth? Where are you seeing in terms of the spectrum? Are people, are companies, you know, trying to do more in terms of augmentation with AI? Are they trying to do more sort of\\\\\", \\\\\"shifting or replacement with AI, what are the things that are driving that? What are the things that they may start down the path of saying, hey, we\\'re looking to do replacement, and certain unexpected things, organizational things, certain process things, certain psychological things are kind of getting in that way, or allowing it to happen, because it is different than they maybe would have expected. anyways.\\\\\\\\n\\\\\\\\nJust again, not sort of a perspective is more of an observation this weekend. Just some stuff I\\'ve seen over the last couple of weeks and it does get me sort of thinking of like, I think we\\'re gonna have to be a little more flexible, a little more understanding of just the dynamics that this is not just what can the technology do, but what is the impact in terms of people understanding what your goals are, people accepting what your goals are, people.\\\\\", \\\\\"you know, measuring themselves as individuals against what tools can do. You know, people tend to have very high expectations of themselves or, or, you know, beliefs in themselves versus being very critical of what things that either could augment or replace certain things can do. And, you know, we see this with technology all the time. So really curious what other people are seeing. Just some stuff that I\\'ve started to see as I, you know, deal with, with companies and talk to people around the world and so forth. So anyways, with that, wrap it up.\\\\\\\\n\\\\\\\\nBrian Gracely (24:09.984)\\\\\\\\nHope everybody\\'s doing well. Hope everybody\\'s April is going well. with that, I will wrap it up and we\\'ll talk to you next week.\\\\\"]\", \"[\\\\\"Aaron Delp (00:01.004)\\\\\\\\nGood morning, good evening, if you are and welcome back to the Cloudcast. We\\'re coming to you live from our massive Cloudcast studios here in Raleigh, North Carolina. And it is just Aaron this week, no Brian. But we have a really fascinating topic today of something that\\'s Brian and I have been kind of kicking around in our heads on the sides and kind of having signed conversations of this whole concept of, DevOps has been around for a while and then platform engineering turns into something for a while. But then what\\'s next?\\\\\\\\n\\\\\\\\nAnd also how do they interact and why we even had problems and needed some of those next steps, right? And so we\\'re going to kind of explore that space a little bit today. In order to do that, we have Mark Friedle, co-CEO and co-founder at Kodiak. So first of all, welcome to the show, Mark, and give everyone a quick introduction, please.\\\\\\\\n\\\\\\\\nMark (00:51.552)\\\\\\\\nYeah, thanks, Aaron. Glad to be here.\\\\\", \\\\\"Like you just mentioned, I\\'m the co-CEO and co-founder of Kodiak. We\\'re a DevOps platform, at least that\\'s the easiest way to say it, but really it was designed out of the, it was really the brainchild of software engineers and architects that were working toward, know, through that space that got more and more complicated, that got more and more snowballing. Then we ran into the fact that there were many things happening in the industry that all kind of came together like,\\\\\\\\n\\\\\\\\nfor instance, infrastructure as code, like containerization, Kubernetes, big data, cloud, all those things are sitting there saying, streaming for, why are we doing a lot of this stuff by hand? And thus came Kodiak. And anybody that\\'s gotten into even the question of, hey, should we use a platform for this? Probably knows exactly what I\\'m talking about. At some point, people turn around and they say, enough\\'s enough. And that\\'s where we were when we started this thing. We said, look, this is crazy.\\\\\", \\\\\"We\\'ve got to figure out a better way to get through this stuff.\\\\\\\\n\\\\\\\\nAaron Delp (01:52.643)\\\\\\\\nYeah, yeah. And maybe let\\'s start there then too, because I definitely want to dig into the tech a little bit, but let\\'s kind of start with the problem. Because the way I\\'ve kind of always phrased this, mean, just like anything else in tech, there\\'s always like your classic S curve, right? Like it\\'s a very bespoke solution and you\\'re trying to figure it out. And then you kind of hit that commoditization and where the platforms and the standardization comes in. And then you got full end, full blown commoditization at the top.\\\\\\\\n\\\\\\\\nMark (02:09.382)\\\\\\\\nyou\\\\\", \\\\\"Aaron Delp (02:20.758)\\\\\\\\nLike we\\'ve like I said, we\\'ve been seeing this problem for a while. But I mean, there\\'s been lots of labels all for kind of sort of the same space or slightly adjacent spaces, whether it\\'s infrastructure is code, whether it\\'s platform engineering, whether it\\'s DevOps, and then you\\'re a big proponent of SDLC. So the know, software lifecycle and how does that kind of fit in to all of this? And what\\'s the problem you\\'re ultimately trying to solve here?\\\\\\\\n\\\\\\\\nMark (02:28.675)\\\\\\\\nWell, SCLC was a great place to start with that because we believe that\\'s the common language that all these guys need to speak. So.\\\\\", \\\\\"I\\'ve got folks on one side of the fence putting together infrastructure and writing infrastructure as code, authoring that. However brilliantly or not so brilliantly it\\'s being done, it\\'s being done. But we have on the other side a bunch of people doing application development and application design. If you\\'ve ever been an application developer or architect who is speaking with your deployment system or your SRE, there\\'s a lot of conversations that need to be had there. In fact,\\\\\", \\\\\"There\\'s usually deployment meetings to try to coordinate that kind of stuff. And then on top of that, you have the cloud providers, which when it comes to commoditization, obviously Azure and AWS wouldn\\'t know anything about commodity anything. Of course, they\\'re entirely unique from server to server and system to system. But the reality is that from the perspective of I\\'ve got software to run.\\\\\\\\n \\\\\\\\nThere are, there is a way to commoditize that and be able to say, look, ultimately I need to know where my stuff is. need memory, need CPU, need, I need response time and I need geography and I need to be able to stand it up and put it down. So with those three things alone, not to mention all the other people that are involved in the approval process and the release process and everything. If everybody\\'s speaking SDLC,\\\\\", \\\\\"you\\'ve got a fighting chance for everybody communicating the same language. And so that was a really great place for great places to start with this thing and kind of centralize a platform. And the other thing I\\'ll add to that, which is being in the industry, like I mentioned, I\\'m a software person, a couple of decades of software architecture and that kind of stuff. And I\\'ve also been up and down through management and entrepreneurship here and there. What we find though is that\\\\\\\\n\\\\\\\\nMark (04:35.711)\\\\\\\\nthroughout these decades, any software person that you speak to that is worth their salt will chime in about the notion of separation of concerns and the notion of, hey, that\\'s business logic versus that\\'s implementation, that\\'s engineering versus that\\'s business. That separation and decoupling, that word is a big one, I mean, that is a source of pride and differentiation and distinction in the software community.\\\\\", \\\\\"However, when it comes to the business of software itself, somehow that gets dropped out. And somehow there are blurred lines from the business of managing software to the implementation of managing software. And so if you were to say, hey, back in the 60s, we figured out how to write software and deploy software in many different ways, but let\\'s just speak about NASA. They had enormous ways to move forward, ways to manage it.\\\\\\\\n\\\\\\\\nerrors and all kinds of other things, they were bound to all of their implementation. suddenly, this was only just a few years ago, we finally have the ability to say, we have infrastructure as code and we have cloud providers and we\\'ve decoupled ourselves from who\\'s running these things. And so that ability to say, well, these different pieces suddenly allow us the ability to say, right now we could separate the business of software from\\\\\", \\\\\"the implementation of software, the business of software, which has not changed. I mean, what\\'s the requirement? I got to run my stuff. I want this version running over here. I need this much resources underneath it. And it needs to stand up and stay stood up. And if there\\'s something wrong with it, tell me about it. The implementation of it, are you running on cloud? Are you running on your own services? Are running in the back room? What version of Apache windows, et cetera?\\\\\\\\n\\\\\\\\nAll that stuff is implementation. And suddenly today we have the ability to say, well, maybe that can be a commodity. If we\\'re speaking the same language everywhere, that\\'s really where we\\'re coming from. think that\\'s where, at least from my perspective, it\\'s one way of describing the emphasis we\\'ve seen going into platform engineering recently.\\\\\", \\\\\"Aaron Delp (06:51.244)\\\\\\\\nYeah, that makes sense. And also, a quick side note. I want to dig into this further, but you have a really interesting origin story with your co-CEO as well when it comes to starting the company. so tell everyone a little bit about how passionately you believe this and how far you went. I\\'ll just phrase it that way. With starting the company.\\\\\\\\n\\\\\\\\nMark (07:03.828)\\\\\\\\nYes.\\\\\\\\n\\\\\\\\nYeah, well, we went through a lot of trap, you know, initially, then Ben and I had been Gazi was my co CEO co founder. He and I had worked together several times in the oil and gas community. And we started doing a couple projects together. But we both had this bug, you know, and it was both, you know, what I\\'d mentioned earlier that this is getting to be so bad. And some of it\\'s so difficult to do the things we want to do. If you\\'ve ever had a project that you want to do on your own.\\\\\", \\\\\"you realize like, well, I can start the concept a little bit, but I know that I\\'m going to spend all my time doing the stuff around the idea and not the idea itself. So anyway, we realized the opportunity. I got into Kubernetes and started thinking, my God, the promise is enormous. In fact, don\\'t think this is one of those times. I don\\'t think I\\'m ever going to go back. So we talked about it. We talked about building a company. I found a customer and this guy was willing to put it up and pay us for this contract. And so I said, here it is. Here\\'s the vehicle.\\\\\", \\\\\"Ben calls me up, we\\'d thrown these ideas around, but Ben calls me up about a couple weeks later and says, all right, I got a buyer on my house. And I thought, well, yeah, I was talking about doing this for a long time, but Jesus, we better get, we actually have to do this. This is real. So we bought RVs, moved out to Texas right out in the middle of nowhere and went dark for a couple of years. And we realized like, I don\\'t know when we\\'re going to get done with this thing. I don\\'t know when.\\\\\", \\\\\"exactly we\\'re going to have that MVP, it was, you know, initially it\\'s really nice to be able to say, well, we\\'re on our own steam, we\\'re doing this thing the way we know it needs to be done, we\\'re redesigning and some of the discussions we had were, it was just fun and, you know, exciting to be on the, really chasing that intellectual thing. But there we were, I mean, we\\'re running on our own money, our own steam, and then we finally chased down some investors and got some seed funding and, you know, kind of way it went, very slowly.\\\\\\\\n\\\\\\\\nMark (09:06.357)\\\\\\\\nTwo guys trying to build a platform is especially, you know, something that\\'s changing some of the, the O for the general business of software. It\\'s, it\\'s a tough thing to move right out of the gate and it\\'s a confidence game. So it\\'s been, it\\'s been a challenge.\\\\\\\\n\\\\\\\\nAaron Delp (09:21.144)\\\\\\\\nYeah, yeah. And further clarifying question though, this was separate RVs, not the same RV, correct?\\\\\", \\\\\"Mark (09:28.545)\\\\\\\\nYeah, Ben moved his family into an RV. He\\'s got two kids and a wife and a dog. I\\'ve just got the dog. And so I put my place in, I live in Tampa, I put the condo up for rent, bought the RV, moved out to Houston. And we had our separate little work offices there. Mine, obviously, one guy and a dog, perfect for an RV. And I recommend it. Anybody\\'s got the opportunity to do that. cut the budget right down. You give yourself an enormous amount of opportunity to kind of make the moves you want to.\\\\\\\\n\\\\\\\\nAaron Delp (09:46.113)\\\\\\\\nNice.\\\\\\\\n\\\\\\\\nMark (09:58.26)\\\\\\\\nWife, two kids and a dog, you different story. You got to really want it.\\\\\\\\n\\\\\\\\nAaron Delp (10:02.92)\\\\\\\\nAbsolutely. That is a different level of commitment for sure. So let\\'s get back to these trends though because\\\\\", \\\\\"I see, yeah, like it\\'s interesting. feel like this whole, I\\'m just going to use this idea of friction, friction, whether it\\'s at the application layer, friction at the operations layer has just been around for so long. Everyone is bought in to the concepts of infrastructure as code and platform engineering, and then just Kubernetes at its most fundamental layer. But everyone kind of always steps back and kind of goes, well,\\\\\\\\n\\\\\\\\nbut it\\'s pretty complex, right? And then you had microservices, you know, in this loose coupling of all the services, you know, that doesn\\'t make it any easier as well, right? And so when it comes to development of this, especially if you\\'re trying to recreate an environment, well, I mean, like, what if you have 20, 30, 40, 50 microservices that all combine together to build the app? Well, how do you build that?\\\\\\\\n\\\\\\\\nMark (10:48.027)\\\\\\\\nYeah.\\\\\", \\\\\"Aaron Delp (11:06.868)\\\\\\\\nRight. And so like, especially when I\\'m thinking about like the build pipeline for something like this, like, am I going down the right path with something like this? When you\\'re talking about like, there\\'s, there\\'s like the central project, which is like, let\\'s say your microservice, but then there\\'s all the other stuff. Right. And is that what you\\'re trying to solve for here?\\\\\\\\n\\\\\\\\nMark (11:16.963)\\\\\\\\nyeah. Yeah, absolutely. Well, I think, I think what.\\\\\\\\n\\\\\\\\nYou know, one way of looking at it is we were talking a little bit before about bespoke versus customizable versus configurable. That\\'s really the question, especially to anybody building a platform saying, well, approach are you taking? And a lot of people that set out on that path, I think there\\'s a very subtle differentiator that\\'s really important. One is I\\'m going to go bespoke, which basically is saying,\\\\\", \\\\\"I\\'ve got one size fits all. It\\'s my script. It\\'s my stuff. It\\'s a black box to you. You hit the go button and boom, it just stands itself up and I hope you trust me on that. And most people I\\'ve talked to, myself included, are going to hear that and say, no. There\\'s the occasional time where that works. And if you\\'re an internal, if you\\'re running an internal platform, maybe that is great because you\\'ve got a platform team that\\'s constantly managing that and nobody else in the company wants to know anything about that.\\\\\\\\n \\\\\\\\nAaron Delp (12:09.344)\\\\\\\\nYes.\\\\\", \\\\\"Mark (12:20.865)\\\\\\\\nBut if your target market are actual engineers and architects that, if nothing else, have a lot of say or need a lot of say in how it\\'s configured, the bespoke model isn\\'t really the greatest. The other model, is open configuration, is another one, which is sort of the other end of the spectrum. It says, all right, I can do whatever I want. You\\'re giving me a thin little wrapper over all of the tech. And I\\'ll just go in there and I can tweak and adjust and play everything I want to.\\\\\\\\n\\\\\\\\nAnd somewhere in between is there\\'s a sweet spot in there that says, I\\'m going to make the very simple, the common stuff simple, and I\\'m going to make the complicated or rare stuff possible. You get an enormous amount of mileage out of that. If you can say, I\\'m not designing a bespoke model, and I\\'m not designing an open, just open,\\\\\", \\\\\"configuration framework, but instead I\\'m developing a tool set with the goal being how much can I propel you? How quickly can we get the things that we know you need done done so that you can move on to the next thing? It\\'s one thing to say, hey, we saved a little bit of time building this. It\\'s another thing to say, wow, when the difference between doing this was 18 phone calls and three meetings and a month and a half of work, and now it\\'s five minutes of bam.\\\\\\\\n\\\\\\\\nI can do things that I didn\\'t think were, I may not have had the other discussion about. Like one of the examples I bring up is the, you know, the, if it took a yaml file to here, take your, take your glass and bend your elbow and take a sip, there would be no such thing as cocktail parties. There would be a lot of people saying, well, I got to drink a drink of liquid and I can do that. And that\\'s great. I know how to do that. And I\\'ve got a team of people that make sure that that happens.\\\\\", \\\\\"Aaron Delp (13:54.946)\\\\\\\\nHeheheheh...\\\\\\\\n\\\\\\\\nMark (14:07.007)\\\\\\\\nSay, all right, fine. But once it\\'s intuitive and it\\'s part of your makeup, like nobody I know is wasting their time trying to figure out how to balance that glass in their hand, that\\'s done. So they\\'re having a conversation. Now we\\'re meeting people, we\\'re talking about business, we\\'re setting up events. It\\'s a whole different evolution that happens when that stuff is second nature. And that\\'s what we\\'re working toward. Like how quick can you get...\\\\\", \\\\\"conception into reality. when it\\'s intuitive and when it\\'s smooth, you know, I\\'ve mentioned this before and some people like it or don\\'t, but I like the notion of an elegant cyborg. You know, we\\'ve got tech all around us. It happens to be attached to our phones and our PCs. But when it\\'s the brain moving through the arm and the arm does the thing that the brain\\'s thinking, new things happen and they\\'re exciting. And you can\\'t look at tech today with all the stuff that\\'s happening and just think, God, there\\'s so much cool crap out there.\\\\\", \\\\\"and there\\'s so much I want to do, but I\\'m stuck because it takes me four and a half hours just to get started on that stuff. Screw that. Let\\'s put an opinionated framework together that acts as a toolset and not as a bespoke model. So anyway, with that toolset, there\\'s obviously a lot of opinions and you get a lot of mileage out of the 80 % and there\\'s other things, there are most likely will probably be, and we haven\\'t encountered it yet, but there\\'ll probably be some folks that say,\\\\\\\\n\\\\\\\\nI can\\'t or that may not fit that model. again, I\\'m just going on a little bit longer. give me one more item on this, that the ability to say, have a system, it does this thing, it allows you to customize it. It also allows extensibility so that you can say, OK, I can customize this whole stuff. And it really gets me a lot of mileage. And then that thing that I\\'m doing and I really am Snowflake unique on this one point.\\\\\\\\n\\\\\\\\nAaron Delp (15:37.965)\\\\\\\\nAll good.\\\\\", \\\\\"Mark (15:59.294)\\\\\\\\nI need to add a little extension to it. And it\\'s our own custom extension that we had to do. And that\\'s healthy. When that\\'s possible to extend it like that. And you have to ask. You\\'ve gone through the gauntlet of, you really need to write that? Because mean, really, which part of this is really unique for you? And you can realize, wow, well, if we zig here instead of zag, it all fits into the model. Hey, that\\'s great. I think that\\'s really the ideal position there.\\\\\\\\n \\\\\\\\nAaron Delp (16:25.708)\\\\\\\\nNo, that makes, it makes perfect sense. And toss or just kind of add to that. especially when it comes to SREs and the work SES are doing, especially supporting build pipelines. you know, I\\'ve kind of always had this idea that, Kubernetes is a blessing and a curse. it\\'s an amazing application platform. And like, there\\'s always that running joke. It\\'s a, it\\'s a fantastic platform for building platforms. Right. But, but,\\\\\", \\\\\"As long as you\\'re not the one that\\'s doing the care and feeding of the platform, it\\'s great. And, but at the same time, like, is it really like, when you\\'re talking, like, when we talk about reduction of friction, is it top to bottom in the stack? Is it more targeted at specifically at Kubernetes because it has such a perception of being such a bear in the industry? What is your thoughts of like, okay,\\\\\\\\n\\\\\\\\nIf you\\'re tactically attacking it and you\\'re talking to an SRE, like where are you specifically removing the friction in the stack?\\\\\\\\n\\\\\\\\nMark (17:28.99)\\\\\\\\nOkay, the first of all, Kubernetes, we chose as a platform because it offers all those great capabilities. The promise of Kubernetes is phenomenal. It\\'s a modern platform. think the notion that you take, for instance, auto scaling, Kubernetes doesn\\'t own auto scaling. There\\'s plenty of different ways to do that. But back to the business versus the implementation side, if you look at it and say,\\\\\", \\\\\"Today one who deploys software must a get logs get telemetry Auto scale as needed set memory footprints and that kind of thing whether it\\'s kubernetes or not It doesn\\'t matter the the so we chose it because yeah, it\\'s a great platform for developing things. It\\'s however If you\\'ve ever used it it\\'s somewhat cumbersome because there\\'s just a lot to take a lot to keep in mind and and the approach that we took was hey if we\\\\\\\\n\\\\\\\\nIf we look at it sort of like a guy who walks in, know, take your favorite deli. I don\\'t know if you have one or not, but pretend you have your favorite deli. walk in every day. Eventually people recognize you and they remember you. And the first day you walk in and you say, okay, look, it\\'s going to be the roast beef with asiago and cheddar. And you lay out the whole sandwich order, right? After a while, that person remembers your sandwich order. And wouldn\\'t it be nice if they just remembered it the first time?\\\\\", \\\\\"And so that\\'s kind of the thing that Kubernetes isn\\'t necessarily going to do for you. Kubernetes is going to ask you for that whole order every time. And you\\'re like, Jesus, man, I told you about this yesterday. So when you can say, all right, well, I\\'ve got an in-between. I\\'ve got this platform in between me and the ultimate platform. And the ultimate platform, let\\'s just speak about it like it\\'s an assembly compiler.\\\\\\\\n\\\\\\\\nI don\\'t want to write assembly code. In fact, I really don\\'t want to repeat myself. You you know the sandwich I like, give me the usual and give it to me over here. In fact, give me the usual, but cut the crust off. You know, great. Very easy, very quick, very intuitive. And so I think that\\'s really the, you know, the, the, the challenge that I\\'ve run into a bunch of this conversation a lot. I tried deploying the Kubernetes. It wasn\\'t too bad. I set up a service and I was able to get it out there and I said, yeah, that\\'s not too bad at all.\\\\\", \\\\\"Mark (19:39.518)\\\\\\\\nWhen you have one service going to one environment with one bit of config and one version, I mean, it\\'s really, it\\'s not hard to walk through the demo. The challenge is the operational side. And again, back to the friction, you know, like, well, we got to make a change. okay. I got to get that config out of the secret store. I got to change that secret. I got to bring that secret store in and then I got to go back out to this and I got to have to make config change in this file, this file, this file, this file. And then I got to make sure that this lines up with that. And you\\'re doing a lot of.\\\\\", \\\\\"I mean, can be when it\\'s the thing to do, it can be really exhilarating puzzle solving, but, and maybe even a bit of a game to try to make sure I got it this time, you know, but, you know, business-wise, operationally, when you can just say, yeah, make that change and send it out. And if that change had an impact of, you know, 15 different configuration changes that needed to happen there, well, that\\'s not your concern if you\\'ve got a good tool behind you. You know, your concern is make this change, send it out, make it happen.\\\\\\\\n \\\\\\\\nAnd that\\'s really, you know, again, that\\'s really the elegant approach to it that offers so many more opportunities there. anyway, I go on and on about it, but that, yeah, it\\'s that evolution.\\\\\", \\\\\"Aaron Delp (20:48.63)\\\\\\\\nNo, I love it. I love it. Let me ask you this, though. if we kind of so we talked about tech stack, if you will. But the other half of that is always the people. Right. And. Cultures and politics and relationships and org charts and all these other things. Right. What if you\\'re talking about reduction of friction? Sometimes some folks are absolutely on board and that makes perfect business sense. But then there\\'s other folks that might be like, well, hey,\\\\\\\\n\\\\\\\\nMark (21:05.557)\\\\\\\\nWell.\\\\\\\\n\\\\\\\\nAaron Delp (21:18.232)\\\\\\\\nThat\\'s my job or that complexity literally is my job definition. Right. And so how does the culture and organization and relationships all sometimes either have to change or not, or what\\'s things to look out for when we\\'re talking about, you know, this kind of consolidation or optimization, if I use that term as well.\\\\\\\\n\\\\\\\\nMark (21:44.865)\\\\\\\\nI think there\\'s an opportunity in especially for SREs where\\\\\", \\\\\"you let\\'s say with and without a really good friction removing system for instance right whatever that system may be the sre has a lot to do a lot to keep in mind and and some meticulous detail to keep up with not only that a lot of sres live in the\\\\\\\\n\\\\\\\\nno news is good news world where look I don\\'t care about you until it\\'s broken and then when it\\'s broken you\\'re the center of attention and it\\'s not good you know and so the ability to say like well I\\'ve got a better discussion to have with the team apart from is it running or not what anybody really wants to know especially at the you know the communication between the business and engineering that that proverbial gap that that lives there\\\\\", \\\\\"Sometimes it\\'s language, sometimes it\\'s just simply, I\\'m going to you asking you for more money for another server. Here come the tech guys asking me for more compute jargon crap that I don\\'t have the budget for and screw them. But when an SRE can come in and say, hey, I\\'ve been watching your stuff because I had time to set up auto scaling. I had time to watch and monitor utilization. Like a lot of people, little aside, a lot of people I speak to.\\\\\", \\\\\"Spend a lot of time like I met a guy working for a pretty big company said I just spent all my time shutting things down Because I don\\'t know what\\'s in use and not we have an enormous number of servers that are just Running and we\\'re not even sure whether anybody\\'s paying attention to them or even using them. So utilization Alone can be a big deal. We have a feature called zombie mode that Allows you to schedule your stuff to shut down and so we take our dev environments and we started shutting them down on the weekends Well, that\\'s two-seventh of the burn right there, you know\\\\\", \\\\\"Mark (23:36.822)\\\\\\\\nWe started shutting them down at night too. He said, well, you know, if you\\'re working with something, we\\'ll keep it on, but we started shutting it down at night. we were, I mean, we were cutting like 40 % off our costs just right then and there by shutting down stuff we weren\\'t paying attention to. So when the SRE can walk in the door and say, I\\'m paying attention to utilization, I\\'m paying attention to auto scaling, and I\\'m paying attention to things like cost per user and cost per transaction, which is a normalized number that you can speak to the business about and say, hey,\\\\\", \\\\\"Last month, our cost per transaction is this and our cost per user is this. If you allow us to make this change, we can drop that cost per user significantly. That\\'s a real conversation to have. Also, I can see where the bottlenecks are. Because I have time and ability to, I spent less time setting it up and more time actually optimizing and paying attention to things. Now I can see we have a bottleneck right here.\\\\\", \\\\\"and it\\'s costing us. I mean, sometimes it\\'s one query that\\'s just loading it up. So I found some really great opportunities so that SRE can actually have a conversation in a sprint planning meeting to say, this one right here will save us an enormous amount of time. Let\\'s prioritize it. When you\\'re working with an SRE that can have conversations with you like that,\\\\\\\\n \\\\\\\\noptimizing your systems, cutting down costs, and actually speaking at a business level about this whole operation of software that you\\'re running instead of just, hey, John, is it working or not? That\\'s an enormous opportunity, both for the business and for those people that are monitoring it.\\\\\\\\n\\\\\\\\nAaron Delp (25:12.674)\\\\\\\\nThat\\'s fantastic. Yeah, I really love that. And I think that\\'s a actually a great place for us to pause, Mark. So let me ask you this final question. If anyone is interested out there and wants to dig in more, what\\'s the best way for folks out there to get started, Mark?\\\\\", \\\\\"Mark (25:14.465)\\\\\\\\nKodiak.io or reach out to me on LinkedIn. Just mark Fridel or look up Kodiak.io on LinkedIn. We\\'re happy to get back to you. We\\'ve got a beta test right now that we\\'re running, finding, looking for people to help us out on to run local clusters.\\\\\\\\n\\\\\\\\non your local machine and do some self-hosting of some AI workloads. So love to get some feedback on that too.\\\\\\\\n\\\\\\\\nAaron Delp (25:50.168)\\\\\\\\nFantastic. Awesome. Well, Mark, thank you very much for your time today. And on behalf of Brian and myself, everyone out there, thank you very much for listening this week. And if you enjoyed the podcast, please tell a friend, please leave us a review if you can, wherever you get your podcasts. And as always, send us feedback. Show at the cloudcast.net. Thank you, everyone, for listening this week. And we will talk to everyone next week.\\\\\\\\n\\\\\\\\nMark (26:13.15)\\\\\\\\nNext slide, folks.\\\\\"]\"]', name='query_database', tool_call_id='call_TLh4uMFJlxBswtMftw5DJveY')]}\n"
     ]
    }
   ],
   "source": [
    "result = await graph.ainvoke(\n",
    "    GraphState(query=\"query all blogs having reference to data management\"), debug=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = await graph.ainvoke(\n",
    "#     GraphState(query=\"visit https://www.thecloudcast.net/\"), debug=False\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "berkeley_ai",
   "language": "python",
   "name": "berkeley_ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
